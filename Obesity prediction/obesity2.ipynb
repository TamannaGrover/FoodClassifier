{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "1080 fits failed out of a total of 6480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1080 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.84391187 0.83782994 0.84463476 ... 0.84228705 0.85625711 0.83807156]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.8728323699421965\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import unquote, urlparse\n",
    "from urllib.error import HTTPError\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "import shutil\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "data_train = pd.read_csv(r\"D:\\Foundathon\\Obesity prediction\\train.csv\")\n",
    "data_test = pd.read_csv(r\"D:\\Foundathon\\Obesity prediction\\test.csv\")\n",
    "\n",
    "data_train_nans = data_train.dtypes.to_frame().T\n",
    "data_train_nans['DataFrame'] = 'data train'\n",
    "data_test_nans = data_test.dtypes.to_frame().T\n",
    "data_test_nans['DataFrame'] = 'data test'\n",
    "combined_df = pd.concat([data_train_nans, data_test_nans], axis=0, ignore_index=True)\n",
    "\n",
    "data_train_nans = data_train.nunique().to_frame().T\n",
    "data_train_nans['DataFrame'] = 'data train'\n",
    "data_test_nans = data_test.nunique().to_frame().T\n",
    "data_test_nans['DataFrame'] = 'data test'\n",
    "combined_df = pd.concat([data_train_nans, data_test_nans], axis=0, ignore_index=True)\n",
    "\n",
    "data_train.head()\n",
    "\n",
    "num_cols_train = list(data_train.select_dtypes(exclude=['object']).columns)\n",
    "cat_cols_train = list(data_train.select_dtypes(include=['object']).columns)\n",
    "\n",
    "num_cols_test = list(data_test.select_dtypes(exclude=['object']).columns)\n",
    "del num_cols_test[0]\n",
    "cat_cols_test = list(data_test.select_dtypes(include=['object']).columns)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data_train[num_cols_train] = scaler.fit_transform(data_train[num_cols_train])\n",
    "data_test[num_cols_test] = scaler.fit_transform(data_test[num_cols_test])\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "obj_columns = data_train.select_dtypes(include='object').columns.difference(['NObeyesdad'])\n",
    "\n",
    "for col_name in obj_columns:\n",
    "    if data_train[col_name].dtypes == 'object':\n",
    "        data_train[col_name] = labelencoder.fit_transform(data_train[col_name])\n",
    "\n",
    "for col_name in data_test.columns:\n",
    "    if data_test[col_name].dtypes == 'object':\n",
    "        data_test[col_name] = labelencoder.fit_transform(data_test[col_name])\n",
    "\n",
    "X = data_train.drop(['NObeyesdad'], axis=1)\n",
    "y = data_train['NObeyesdad']\n",
    "y = labelencoder.fit_transform(y)\n",
    "X_test = data_test\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "param_grid = {'criterion': ['gini', 'entropy'],\n",
    "              'splitter': ['best', 'random'],\n",
    "              'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'max_features': [None, 'sqrt', 'auto', 'log2', 0.5, 0.7]}  # Add numeric values as needed\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = best_model.predict(X_val)\n",
    "accuracy = accuracy_score(Y_val, Y_pred)\n",
    "print(f\"Accuracy on validation set: {accuracy}\")\n",
    "\n",
    "final_predictions = best_model.predict(X_test)\n",
    "\n",
    "result_df = pd.DataFrame({'id': range(1, len(final_predictions) + 1), 'NObeyesdad': final_predictions})\n",
    "result_df['NObeyesdad'] = labelencoder.inverse_transform(result_df['NObeyesdad'])\n",
    "result_df.to_csv(\"/kaggle/working/predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['obesity_prediction_model.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model, 'obesity_prediction_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- id\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m         sample_input[col_name] \u001b[38;5;241m=\u001b[39m labelencoder\u001b[38;5;241m.\u001b[39mfit_transform(sample_input[col_name])\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Make prediction\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m prediction_class \u001b[38;5;241m=\u001b[39m labelencoder\u001b[38;5;241m.\u001b[39minverse_transform(prediction)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Class: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:529\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;124;03m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    528\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 529\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    530\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m    531\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:489\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    497\u001b[0m     X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc\n\u001b[0;32m    498\u001b[0m ):\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- id\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "# Load the model\n",
    "best_model = joblib.load('obesity_prediction_model.joblib')\n",
    "\n",
    "# Sample input features\n",
    "sample_input = pd.DataFrame({\n",
    "    'Gender': ['Male'],\n",
    "    'Age': [25],\n",
    "    'Height': [1.75],\n",
    "    'Weight': [70],\n",
    "    'family_history_with_overweight': ['yes'],\n",
    "    'FAVC': ['yes'],\n",
    "    'FCVC': [3],\n",
    "    'NCP': [3],\n",
    "    'CAEC': ['Sometimes'],\n",
    "    'SMOKE': ['no'],\n",
    "    'CH2O': [2.5],\n",
    "    'SCC': ['no'],\n",
    "    'FAF': [1.5],\n",
    "    'TUE': [2],\n",
    "    'CALC': ['no'],\n",
    "    'MTRANS': ['Public_Transportation']\n",
    "})\n",
    "\n",
    "# Assuming num_cols_train is the list of numeric columns in your training data\n",
    "num_cols_train = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
    "\n",
    "# Assuming data_train is the training dataset\n",
    "# Exclude the 'id' column from the training data if it exists\n",
    "data_train = data_train.drop(columns=['id'], errors='ignore')\n",
    "\n",
    "# Ensure that the columns in the sample input match the order in the training data\n",
    "sample_input = sample_input[data_train.columns[:-1]]  # Exclude the target column 'NObeyesdad'\n",
    "\n",
    "# Check if 'id' was in the training data and drop it from the sample input if present\n",
    "if 'id' in data_train.columns:\n",
    "    sample_input = sample_input.drop(columns=['id'], errors='ignore')\n",
    "\n",
    "# Define the scaler, obj_columns, and labelencoder\n",
    "scaler = MinMaxScaler()\n",
    "obj_columns = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS']\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "# Preprocess sample input\n",
    "sample_input[num_cols_train] = scaler.fit_transform(sample_input[num_cols_train])\n",
    "for col_name in obj_columns:\n",
    "    if sample_input[col_name].dtypes == 'object':\n",
    "        sample_input[col_name] = labelencoder.fit_transform(sample_input[col_name])\n",
    "\n",
    "# Make prediction\n",
    "prediction = best_model.predict(sample_input)\n",
    "prediction_class = labelencoder.inverse_transform(prediction)\n",
    "\n",
    "print(f\"Predicted Class: {prediction_class}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
