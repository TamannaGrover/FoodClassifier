{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>24.443011</td>\n",
       "      <td>1.699998</td>\n",
       "      <td>81.669950</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.983297</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.763573</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976473</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.711460</td>\n",
       "      <td>50.165754</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.880534</td>\n",
       "      <td>1.411685</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.910378</td>\n",
       "      <td>no</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>1.673584</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>20.952737</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.274851</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.674061</td>\n",
       "      <td>no</td>\n",
       "      <td>1.467863</td>\n",
       "      <td>0.780199</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.641081</td>\n",
       "      <td>1.914186</td>\n",
       "      <td>93.798055</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.679664</td>\n",
       "      <td>1.971472</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.979848</td>\n",
       "      <td>no</td>\n",
       "      <td>1.967973</td>\n",
       "      <td>0.931721</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20753</th>\n",
       "      <td>20753</td>\n",
       "      <td>Male</td>\n",
       "      <td>25.137087</td>\n",
       "      <td>1.766626</td>\n",
       "      <td>114.187096</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.919584</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.151809</td>\n",
       "      <td>no</td>\n",
       "      <td>1.330519</td>\n",
       "      <td>0.196680</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20754</th>\n",
       "      <td>20754</td>\n",
       "      <td>Male</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20755</th>\n",
       "      <td>20755</td>\n",
       "      <td>Male</td>\n",
       "      <td>20.101026</td>\n",
       "      <td>1.819557</td>\n",
       "      <td>105.580491</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.407817</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.158040</td>\n",
       "      <td>1.198439</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20756</th>\n",
       "      <td>20756</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.852953</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>83.520113</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.671238</td>\n",
       "      <td>1.971472</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.144838</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973834</td>\n",
       "      <td>no</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20757</th>\n",
       "      <td>20757</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.680376</td>\n",
       "      <td>1.816547</td>\n",
       "      <td>118.134898</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.003563</td>\n",
       "      <td>no</td>\n",
       "      <td>0.684487</td>\n",
       "      <td>0.713823</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20758 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Gender        Age    Height      Weight  \\\n",
       "0          0    Male  24.443011  1.699998   81.669950   \n",
       "1          1  Female  18.000000  1.560000   57.000000   \n",
       "2          2  Female  18.000000  1.711460   50.165754   \n",
       "3          3  Female  20.952737  1.710730  131.274851   \n",
       "4          4    Male  31.641081  1.914186   93.798055   \n",
       "...      ...     ...        ...       ...         ...   \n",
       "20753  20753    Male  25.137087  1.766626  114.187096   \n",
       "20754  20754    Male  18.000000  1.710000   50.000000   \n",
       "20755  20755    Male  20.101026  1.819557  105.580491   \n",
       "20756  20756    Male  33.852953  1.700000   83.520113   \n",
       "20757  20757    Male  26.680376  1.816547  118.134898   \n",
       "\n",
       "      family_history_with_overweight FAVC      FCVC       NCP        CAEC  \\\n",
       "0                                yes  yes  2.000000  2.983297   Sometimes   \n",
       "1                                yes  yes  2.000000  3.000000  Frequently   \n",
       "2                                yes  yes  1.880534  1.411685   Sometimes   \n",
       "3                                yes  yes  3.000000  3.000000   Sometimes   \n",
       "4                                yes  yes  2.679664  1.971472   Sometimes   \n",
       "...                              ...  ...       ...       ...         ...   \n",
       "20753                            yes  yes  2.919584  3.000000   Sometimes   \n",
       "20754                             no  yes  3.000000  4.000000  Frequently   \n",
       "20755                            yes  yes  2.407817  3.000000   Sometimes   \n",
       "20756                            yes  yes  2.671238  1.971472   Sometimes   \n",
       "20757                            yes  yes  3.000000  3.000000   Sometimes   \n",
       "\n",
       "      SMOKE      CH2O SCC       FAF       TUE       CALC  \\\n",
       "0        no  2.763573  no  0.000000  0.976473  Sometimes   \n",
       "1        no  2.000000  no  1.000000  1.000000         no   \n",
       "2        no  1.910378  no  0.866045  1.673584         no   \n",
       "3        no  1.674061  no  1.467863  0.780199  Sometimes   \n",
       "4        no  1.979848  no  1.967973  0.931721  Sometimes   \n",
       "...     ...       ...  ..       ...       ...        ...   \n",
       "20753    no  2.151809  no  1.330519  0.196680  Sometimes   \n",
       "20754    no  1.000000  no  2.000000  1.000000  Sometimes   \n",
       "20755    no  2.000000  no  1.158040  1.198439         no   \n",
       "20756    no  2.144838  no  0.000000  0.973834         no   \n",
       "20757    no  2.003563  no  0.684487  0.713823  Sometimes   \n",
       "\n",
       "                      MTRANS           NObeyesdad  \n",
       "0      Public_Transportation  Overweight_Level_II  \n",
       "1                 Automobile        Normal_Weight  \n",
       "2      Public_Transportation  Insufficient_Weight  \n",
       "3      Public_Transportation     Obesity_Type_III  \n",
       "4      Public_Transportation  Overweight_Level_II  \n",
       "...                      ...                  ...  \n",
       "20753  Public_Transportation      Obesity_Type_II  \n",
       "20754  Public_Transportation  Insufficient_Weight  \n",
       "20755  Public_Transportation      Obesity_Type_II  \n",
       "20756             Automobile  Overweight_Level_II  \n",
       "20757  Public_Transportation      Obesity_Type_II  \n",
       "\n",
       "[20758 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sweetviz as sv\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "df_train=pd.read_csv(\"D:\\\\Foundathon\\\\Obesity prediction\\\\train.csv\")\n",
    "df_test=pd.read_csv(\"D:\\\\Foundathon\\\\Obesity prediction\\\\test.csv\")\n",
    "sample_submission=pd.read_csv(\"D:\\\\Foundathon\\\\Obesity prediction\\\\sample_submission.csv\")\n",
    "#report = sv.analyze(df_train)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS']\n",
    "numerical_features = [feature for feature in df_test.columns[1:] if feature not in categorical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in categorical_features:\n",
    "    dummies = pd.get_dummies(df_test[feature], prefix=feature, dtype=int)\n",
    "    df_test = pd.concat([dummies, df_test], axis=1)\n",
    "    \n",
    "    dummies = pd.get_dummies(df_train[feature], prefix=feature, dtype=int)\n",
    "    df_train = pd.concat([dummies, df_train], axis=1)\n",
    "\n",
    "df_test.drop(columns=categorical_features, inplace=True)\n",
    "df_train.drop(columns=categorical_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Overweight_Level_II', 'Normal_Weight', 'Insufficient_Weight',\n",
       "       'Obesity_Type_III', 'Obesity_Type_II', 'Overweight_Level_I',\n",
       "       'Obesity_Type_I'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummies = pd.get_dummies(df_train['NObeyesdad'], prefix='target', dtype=int)\n",
    "# df_train = pd.concat([df_train, dummies], axis=1)\n",
    "# df_train.drop(columns=['NObeyesdad'], inplace=True)\n",
    "\n",
    "# target_columns = [elem for elem in df_train.columns if elem.startswith('target')]\n",
    "target_columns = 'NObeyesdad'\n",
    "df_train[target_columns].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 'Overweight_Level_II')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encodeTarget(obesity):\n",
    "    dictObesity = {'Insufficient_Weight' : 0, \n",
    "                  'Normal_Weight' : 1,\n",
    "                  'Overweight_Level_I': 2,\n",
    "                  'Overweight_Level_II' : 3,\n",
    "                  'Obesity_Type_I' : 4,\n",
    "                  'Obesity_Type_II' : 5,\n",
    "                  'Obesity_Type_III' : 6}\n",
    "    return(dictObesity[obesity])\n",
    "\n",
    "def unencodeTarget(key):\n",
    "    revertedDictObesity = {0: 'Insufficient_Weight',\n",
    "                           1: 'Normal_Weight',\n",
    "                           2: 'Overweight_Level_I',\n",
    "                           3: 'Overweight_Level_II',\n",
    "                           4: 'Obesity_Type_I',\n",
    "                           5: 'Obesity_Type_II',\n",
    "                           6: 'Obesity_Type_III'}\n",
    "    return(revertedDictObesity[key])\n",
    "\n",
    "encodeTarget('Overweight_Level_II'), unencodeTarget(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[target_columns] = df_train[target_columns].map(lambda x : encodeTarget(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MTRANS_Automobile', 'MTRANS_Bike', 'MTRANS_Motorbike',\n",
      "       'MTRANS_Public_Transportation', 'MTRANS_Walking', 'CALC_Frequently',\n",
      "       'CALC_Sometimes', 'CALC_no', 'SCC_no', 'SCC_yes', 'SMOKE_no',\n",
      "       'SMOKE_yes', 'CAEC_Always', 'CAEC_Frequently', 'CAEC_Sometimes',\n",
      "       'CAEC_no', 'FAVC_no', 'FAVC_yes', 'family_history_with_overweight_no',\n",
      "       'family_history_with_overweight_yes', 'Gender_Female', 'Gender_Male',\n",
      "       'id', 'Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE',\n",
      "       'NObeyesdad'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_to_drop = 'CALC_Always'\n",
    "# if column_to_drop in df_test.columns:\n",
    "#     df_test.drop(column_to_drop, axis=1, inplace=True)\n",
    "#     print(f\"Column '{column_to_drop}' successfully dropped.\")\n",
    "# else:\n",
    "#     print(f\"Column '{column_to_drop}' not found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE()\n",
    "\n",
    "X, y = df_train.drop([target_columns, 'id'], axis = 1), df_train[target_columns]\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "\n",
    "df_train_resampled = pd.concat([X, y], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MTRANS_Automobile</th>\n",
       "      <th>MTRANS_Bike</th>\n",
       "      <th>MTRANS_Motorbike</th>\n",
       "      <th>MTRANS_Public_Transportation</th>\n",
       "      <th>MTRANS_Walking</th>\n",
       "      <th>CALC_Frequently</th>\n",
       "      <th>CALC_Sometimes</th>\n",
       "      <th>CALC_no</th>\n",
       "      <th>SCC_no</th>\n",
       "      <th>SCC_yes</th>\n",
       "      <th>...</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>24.443011</td>\n",
       "      <td>1.699998</td>\n",
       "      <td>81.669950</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.983297</td>\n",
       "      <td>2.763573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976473</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.711460</td>\n",
       "      <td>50.165754</td>\n",
       "      <td>1.880534</td>\n",
       "      <td>1.411685</td>\n",
       "      <td>1.910378</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>1.673584</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20.952737</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.274851</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.674061</td>\n",
       "      <td>1.467863</td>\n",
       "      <td>0.780199</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>31.641081</td>\n",
       "      <td>1.914186</td>\n",
       "      <td>93.798055</td>\n",
       "      <td>2.679664</td>\n",
       "      <td>1.971472</td>\n",
       "      <td>1.979848</td>\n",
       "      <td>1.967973</td>\n",
       "      <td>0.931721</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28317</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29.009026</td>\n",
       "      <td>1.757554</td>\n",
       "      <td>118.204862</td>\n",
       "      <td>2.131753</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.046959</td>\n",
       "      <td>0.344678</td>\n",
       "      <td>0.416458</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28318</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>26.965544</td>\n",
       "      <td>1.772594</td>\n",
       "      <td>118.169420</td>\n",
       "      <td>2.966159</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.096761</td>\n",
       "      <td>0.680259</td>\n",
       "      <td>0.192286</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28319</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>27.266287</td>\n",
       "      <td>1.791737</td>\n",
       "      <td>120.151967</td>\n",
       "      <td>2.638510</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.162104</td>\n",
       "      <td>1.277627</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28320</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25.427505</td>\n",
       "      <td>1.763019</td>\n",
       "      <td>115.430080</td>\n",
       "      <td>2.043766</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.151746</td>\n",
       "      <td>1.089455</td>\n",
       "      <td>1.054899</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28321</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25.616661</td>\n",
       "      <td>1.769846</td>\n",
       "      <td>115.122092</td>\n",
       "      <td>1.928408</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.132148</td>\n",
       "      <td>1.365613</td>\n",
       "      <td>0.660594</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28322 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MTRANS_Automobile  MTRANS_Bike  MTRANS_Motorbike  \\\n",
       "0                      0            0                 0   \n",
       "1                      1            0                 0   \n",
       "2                      0            0                 0   \n",
       "3                      0            0                 0   \n",
       "4                      0            0                 0   \n",
       "...                  ...          ...               ...   \n",
       "28317                  1            0                 0   \n",
       "28318                  1            0                 0   \n",
       "28319                  1            0                 0   \n",
       "28320                  0            0                 0   \n",
       "28321                  0            0                 0   \n",
       "\n",
       "       MTRANS_Public_Transportation  MTRANS_Walking  CALC_Frequently  \\\n",
       "0                                 1               0                0   \n",
       "1                                 0               0                0   \n",
       "2                                 1               0                0   \n",
       "3                                 1               0                0   \n",
       "4                                 1               0                0   \n",
       "...                             ...             ...              ...   \n",
       "28317                             0               0                0   \n",
       "28318                             0               0                0   \n",
       "28319                             0               0                0   \n",
       "28320                             1               0                0   \n",
       "28321                             1               0                0   \n",
       "\n",
       "       CALC_Sometimes  CALC_no  SCC_no  SCC_yes  ...  Gender_Male        Age  \\\n",
       "0                   1        0       1        0  ...            1  24.443011   \n",
       "1                   0        1       1        0  ...            0  18.000000   \n",
       "2                   0        1       1        0  ...            0  18.000000   \n",
       "3                   1        0       1        0  ...            0  20.952737   \n",
       "4                   1        0       1        0  ...            1  31.641081   \n",
       "...               ...      ...     ...      ...  ...          ...        ...   \n",
       "28317               1        0       1        0  ...            1  29.009026   \n",
       "28318               1        0       1        0  ...            1  26.965544   \n",
       "28319               1        0       1        0  ...            1  27.266287   \n",
       "28320               1        0       1        0  ...            1  25.427505   \n",
       "28321               1        0       1        0  ...            1  25.616661   \n",
       "\n",
       "         Height      Weight      FCVC       NCP      CH2O       FAF       TUE  \\\n",
       "0      1.699998   81.669950  2.000000  2.983297  2.763573  0.000000  0.976473   \n",
       "1      1.560000   57.000000  2.000000  3.000000  2.000000  1.000000  1.000000   \n",
       "2      1.711460   50.165754  1.880534  1.411685  1.910378  0.866045  1.673584   \n",
       "3      1.710730  131.274851  3.000000  3.000000  1.674061  1.467863  0.780199   \n",
       "4      1.914186   93.798055  2.679664  1.971472  1.979848  1.967973  0.931721   \n",
       "...         ...         ...       ...       ...       ...       ...       ...   \n",
       "28317  1.757554  118.204862  2.131753  3.000000  2.046959  0.344678  0.416458   \n",
       "28318  1.772594  118.169420  2.966159  3.000000  2.096761  0.680259  0.192286   \n",
       "28319  1.791737  120.151967  2.638510  3.000000  2.162104  1.277627  0.005161   \n",
       "28320  1.763019  115.430080  2.043766  3.000000  2.151746  1.089455  1.054899   \n",
       "28321  1.769846  115.122092  1.928408  3.000000  2.132148  1.365613  0.660594   \n",
       "\n",
       "       NObeyesdad  \n",
       "0               3  \n",
       "1               1  \n",
       "2               0  \n",
       "3               6  \n",
       "4               3  \n",
       "...           ...  \n",
       "28317           5  \n",
       "28318           5  \n",
       "28319           5  \n",
       "28320           5  \n",
       "28321           5  \n",
       "\n",
       "[28322 rows x 31 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   | colsam... |   gamma   |  lambda_  | learni... | max_depth | min_ch... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.889    \u001b[0m | \u001b[0m3.745    \u001b[0m | \u001b[0m0.8704   \u001b[0m | \u001b[0m3.66     \u001b[0m | \u001b[0m6.388    \u001b[0m | \u001b[0m0.05525  \u001b[0m | \u001b[0m4.404    \u001b[0m | \u001b[0m0.5808   \u001b[0m | \u001b[0m0.9331   \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.89     \u001b[0m | \u001b[95m6.011    \u001b[0m | \u001b[95m0.7248   \u001b[0m | \u001b[95m0.1029   \u001b[0m | \u001b[95m9.729    \u001b[0m | \u001b[95m0.2514   \u001b[0m | \u001b[95m4.911    \u001b[0m | \u001b[95m1.818    \u001b[0m | \u001b[95m0.5917   \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.894    \u001b[0m | \u001b[95m3.042    \u001b[0m | \u001b[95m0.6149   \u001b[0m | \u001b[95m2.16     \u001b[0m | \u001b[95m3.621    \u001b[0m | \u001b[95m0.1874   \u001b[0m | \u001b[95m4.255    \u001b[0m | \u001b[95m2.921    \u001b[0m | \u001b[95m0.6832   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.892    \u001b[0m | \u001b[0m4.561    \u001b[0m | \u001b[0m0.7711   \u001b[0m | \u001b[0m0.9984   \u001b[0m | \u001b[0m5.628    \u001b[0m | \u001b[0m0.1818   \u001b[0m | \u001b[0m3.418    \u001b[0m | \u001b[0m6.075    \u001b[0m | \u001b[0m0.5853   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.888    \u001b[0m | \u001b[0m0.6505   \u001b[0m | \u001b[0m0.8693   \u001b[0m | \u001b[0m4.828    \u001b[0m | \u001b[0m8.276    \u001b[0m | \u001b[0m0.09834  \u001b[0m | \u001b[0m3.879    \u001b[0m | \u001b[0m6.842    \u001b[0m | \u001b[0m0.7201   \u001b[0m |\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m0.9      \u001b[0m | \u001b[95m1.22     \u001b[0m | \u001b[95m0.5971   \u001b[0m | \u001b[95m0.1719   \u001b[0m | \u001b[95m9.184    \u001b[0m | \u001b[95m0.08505  \u001b[0m | \u001b[95m8.963    \u001b[0m | \u001b[95m3.117    \u001b[0m | \u001b[95m0.76     \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.88     \u001b[0m | \u001b[0m5.467    \u001b[0m | \u001b[0m0.4109   \u001b[0m | \u001b[0m4.848    \u001b[0m | \u001b[0m7.976    \u001b[0m | \u001b[0m0.2825   \u001b[0m | \u001b[0m11.05    \u001b[0m | \u001b[0m5.979    \u001b[0m | \u001b[0m0.9609   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.894    \u001b[0m | \u001b[0m0.8849   \u001b[0m | \u001b[0m0.4176   \u001b[0m | \u001b[0m0.2261   \u001b[0m | \u001b[0m3.928    \u001b[0m | \u001b[0m0.1227   \u001b[0m | \u001b[0m5.442    \u001b[0m | \u001b[0m8.287    \u001b[0m | \u001b[0m0.6784   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.885    \u001b[0m | \u001b[0m2.809    \u001b[0m | \u001b[0m0.6256   \u001b[0m | \u001b[0m0.7046   \u001b[0m | \u001b[0m8.22     \u001b[0m | \u001b[0m0.03162  \u001b[0m | \u001b[0m11.88    \u001b[0m | \u001b[0m7.722    \u001b[0m | \u001b[0m0.5994   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.889    \u001b[0m | \u001b[0m0.05522  \u001b[0m | \u001b[0m0.7893   \u001b[0m | \u001b[0m3.534    \u001b[0m | \u001b[0m7.561    \u001b[0m | \u001b[0m0.2337   \u001b[0m | \u001b[0m3.666    \u001b[0m | \u001b[0m3.585    \u001b[0m | \u001b[0m0.5579   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.878    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4793   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m9.412    \u001b[0m | \u001b[0m0.01217  \u001b[0m | \u001b[0m8.912    \u001b[0m | \u001b[0m1.166    \u001b[0m | \u001b[0m0.7647   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.88     \u001b[0m | \u001b[0m5.009    \u001b[0m | \u001b[0m0.8238   \u001b[0m | \u001b[0m4.495    \u001b[0m | \u001b[0m1.717    \u001b[0m | \u001b[0m0.2515   \u001b[0m | \u001b[0m7.793    \u001b[0m | \u001b[0m6.433    \u001b[0m | \u001b[0m0.5576   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.899    \u001b[0m | \u001b[0m1.363    \u001b[0m | \u001b[0m0.7042   \u001b[0m | \u001b[0m2.556    \u001b[0m | \u001b[0m1.236    \u001b[0m | \u001b[0m0.0261   \u001b[0m | \u001b[0m5.232    \u001b[0m | \u001b[0m9.713    \u001b[0m | \u001b[0m0.8948   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.895    \u001b[0m | \u001b[0m5.481    \u001b[0m | \u001b[0m0.8474   \u001b[0m | \u001b[0m0.4227   \u001b[0m | \u001b[0m5.043    \u001b[0m | \u001b[0m0.06762  \u001b[0m | \u001b[0m8.316    \u001b[0m | \u001b[0m3.886    \u001b[0m | \u001b[0m0.8115   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.895    \u001b[0m | \u001b[0m2.615    \u001b[0m | \u001b[0m0.792    \u001b[0m | \u001b[0m4.897    \u001b[0m | \u001b[0m2.361    \u001b[0m | \u001b[0m0.2546   \u001b[0m | \u001b[0m9.728    \u001b[0m | \u001b[0m6.517    \u001b[0m | \u001b[0m0.9533   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.878    \u001b[0m | \u001b[0m6.368    \u001b[0m | \u001b[0m0.5681   \u001b[0m | \u001b[0m3.337    \u001b[0m | \u001b[0m7.332    \u001b[0m | \u001b[0m0.2578   \u001b[0m | \u001b[0m8.765    \u001b[0m | \u001b[0m7.395    \u001b[0m | \u001b[0m0.7385   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.893    \u001b[0m | \u001b[0m6.722    \u001b[0m | \u001b[0m0.7654   \u001b[0m | \u001b[0m0.8126   \u001b[0m | \u001b[0m2.162    \u001b[0m | \u001b[0m0.11     \u001b[0m | \u001b[0m3.256    \u001b[0m | \u001b[0m1.191    \u001b[0m | \u001b[0m0.9752   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.877    \u001b[0m | \u001b[0m7.579    \u001b[0m | \u001b[0m0.8808   \u001b[0m | \u001b[0m4.85     \u001b[0m | \u001b[0m7.653    \u001b[0m | \u001b[0m0.2432   \u001b[0m | \u001b[0m9.577    \u001b[0m | \u001b[0m6.768    \u001b[0m | \u001b[0m0.9525   \u001b[0m |\n",
      "| \u001b[95m19       \u001b[0m | \u001b[95m0.902    \u001b[0m | \u001b[95m1.907    \u001b[0m | \u001b[95m0.6678   \u001b[0m | \u001b[95m0.238    \u001b[0m | \u001b[95m9.011    \u001b[0m | \u001b[95m0.1256   \u001b[0m | \u001b[95m8.9      \u001b[0m | \u001b[95m4.093    \u001b[0m | \u001b[95m0.76     \u001b[0m |\n",
      "| \u001b[95m20       \u001b[0m | \u001b[95m0.908    \u001b[0m | \u001b[95m2.467    \u001b[0m | \u001b[95m0.6778   \u001b[0m | \u001b[95m0.02254  \u001b[0m | \u001b[95m7.52     \u001b[0m | \u001b[95m0.07577  \u001b[0m | \u001b[95m8.457    \u001b[0m | \u001b[95m3.353    \u001b[0m | \u001b[95m0.7742   \u001b[0m |\n",
      "| \u001b[95m21       \u001b[0m | \u001b[95m0.909    \u001b[0m | \u001b[95m1.453    \u001b[0m | \u001b[95m0.7389   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m6.616    \u001b[0m | \u001b[95m0.178    \u001b[0m | \u001b[95m7.847    \u001b[0m | \u001b[95m4.237    \u001b[0m | \u001b[95m0.9449   \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.885    \u001b[0m | \u001b[0m1.626    \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m5.623    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m9.545    \u001b[0m | \u001b[0m3.632    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.899    \u001b[0m | \u001b[0m1.998    \u001b[0m | \u001b[0m0.5677   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m7.71     \u001b[0m | \u001b[0m0.2215   \u001b[0m | \u001b[0m7.044    \u001b[0m | \u001b[0m3.942    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.895    \u001b[0m | \u001b[0m1.485    \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m0.8287   \u001b[0m | \u001b[0m7.457    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m8.374    \u001b[0m | \u001b[0m3.976    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.888    \u001b[0m | \u001b[0m2.861    \u001b[0m | \u001b[0m0.3      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m8.477    \u001b[0m | \u001b[0m0.3      \u001b[0m | \u001b[0m8.645    \u001b[0m | \u001b[0m3.126    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.905    \u001b[0m | \u001b[0m2.224    \u001b[0m | \u001b[0m0.6489   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m6.846    \u001b[0m | \u001b[0m0.1639   \u001b[0m | \u001b[0m7.991    \u001b[0m | \u001b[0m3.781    \u001b[0m | \u001b[0m0.859    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.879    \u001b[0m | \u001b[0m1.412    \u001b[0m | \u001b[0m0.3393   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m7.162    \u001b[0m | \u001b[0m0.3      \u001b[0m | \u001b[0m8.005    \u001b[0m | \u001b[0m3.766    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.874    \u001b[0m | \u001b[0m7.448    \u001b[0m | \u001b[0m0.4549   \u001b[0m | \u001b[0m1.164    \u001b[0m | \u001b[0m9.506    \u001b[0m | \u001b[0m0.01664  \u001b[0m | \u001b[0m8.245    \u001b[0m | \u001b[0m6.478    \u001b[0m | \u001b[0m0.9433   \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.888    \u001b[0m | \u001b[0m4.184    \u001b[0m | \u001b[0m0.5103   \u001b[0m | \u001b[0m2.765    \u001b[0m | \u001b[0m4.995    \u001b[0m | \u001b[0m0.1881   \u001b[0m | \u001b[0m4.064    \u001b[0m | \u001b[0m3.205    \u001b[0m | \u001b[0m0.9175   \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.871    \u001b[0m | \u001b[0m7.744    \u001b[0m | \u001b[0m0.535    \u001b[0m | \u001b[0m4.124    \u001b[0m | \u001b[0m7.347    \u001b[0m | \u001b[0m0.03209  \u001b[0m | \u001b[0m11.54    \u001b[0m | \u001b[0m6.735    \u001b[0m | \u001b[0m0.673    \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m0.901    \u001b[0m | \u001b[0m2.321    \u001b[0m | \u001b[0m0.5053   \u001b[0m | \u001b[0m0.2923   \u001b[0m | \u001b[0m7.085    \u001b[0m | \u001b[0m0.07914  \u001b[0m | \u001b[0m7.443    \u001b[0m | \u001b[0m3.933    \u001b[0m | \u001b[0m0.7342   \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.899    \u001b[0m | \u001b[0m2.619    \u001b[0m | \u001b[0m0.8806   \u001b[0m | \u001b[0m0.1582   \u001b[0m | \u001b[0m6.912    \u001b[0m | \u001b[0m0.1261   \u001b[0m | \u001b[0m8.038    \u001b[0m | \u001b[0m2.571    \u001b[0m | \u001b[0m0.5387   \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m0.897    \u001b[0m | \u001b[0m2.467    \u001b[0m | \u001b[0m0.7007   \u001b[0m | \u001b[0m0.3391   \u001b[0m | \u001b[0m6.276    \u001b[0m | \u001b[0m0.279    \u001b[0m | \u001b[0m7.876    \u001b[0m | \u001b[0m3.961    \u001b[0m | \u001b[0m0.8149   \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.906    \u001b[0m | \u001b[0m2.913    \u001b[0m | \u001b[0m0.5626   \u001b[0m | \u001b[0m0.6731   \u001b[0m | \u001b[0m7.612    \u001b[0m | \u001b[0m0.08811  \u001b[0m | \u001b[0m9.277    \u001b[0m | \u001b[0m3.751    \u001b[0m | \u001b[0m0.7584   \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.893    \u001b[0m | \u001b[0m2.719    \u001b[0m | \u001b[0m0.8934   \u001b[0m | \u001b[0m0.3135   \u001b[0m | \u001b[0m7.328    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m8.559    \u001b[0m | \u001b[0m3.849    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m0.905    \u001b[0m | \u001b[0m1.889    \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m6.708    \u001b[0m | \u001b[0m0.03345  \u001b[0m | \u001b[0m7.643    \u001b[0m | \u001b[0m4.225    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m0.894    \u001b[0m | \u001b[0m2.587    \u001b[0m | \u001b[0m0.4447   \u001b[0m | \u001b[0m0.3554   \u001b[0m | \u001b[0m7.645    \u001b[0m | \u001b[0m0.1765   \u001b[0m | \u001b[0m9.799    \u001b[0m | \u001b[0m3.569    \u001b[0m | \u001b[0m0.5808   \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.899    \u001b[0m | \u001b[0m2.24     \u001b[0m | \u001b[0m0.495    \u001b[0m | \u001b[0m0.113    \u001b[0m | \u001b[0m6.488    \u001b[0m | \u001b[0m0.1248   \u001b[0m | \u001b[0m8.264    \u001b[0m | \u001b[0m3.905    \u001b[0m | \u001b[0m0.727    \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.876    \u001b[0m | \u001b[0m8.584    \u001b[0m | \u001b[0m0.3152   \u001b[0m | \u001b[0m1.515    \u001b[0m | \u001b[0m5.982    \u001b[0m | \u001b[0m0.1412   \u001b[0m | \u001b[0m11.07    \u001b[0m | \u001b[0m5.772    \u001b[0m | \u001b[0m0.7155   \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m0.891    \u001b[0m | \u001b[0m2.616    \u001b[0m | \u001b[0m0.4614   \u001b[0m | \u001b[0m0.4754   \u001b[0m | \u001b[0m7.363    \u001b[0m | \u001b[0m0.05934  \u001b[0m | \u001b[0m8.739    \u001b[0m | \u001b[0m3.135    \u001b[0m | \u001b[0m0.6518   \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m0.884    \u001b[0m | \u001b[0m2.36     \u001b[0m | \u001b[0m0.7197   \u001b[0m | \u001b[0m0.8444   \u001b[0m | \u001b[0m8.46     \u001b[0m | \u001b[0m0.01159  \u001b[0m | \u001b[0m8.868    \u001b[0m | \u001b[0m4.22     \u001b[0m | \u001b[0m0.8799   \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m0.906    \u001b[0m | \u001b[0m1.686    \u001b[0m | \u001b[0m0.8215   \u001b[0m | \u001b[0m0.4194   \u001b[0m | \u001b[0m9.087    \u001b[0m | \u001b[0m0.09547  \u001b[0m | \u001b[0m8.007    \u001b[0m | \u001b[0m3.619    \u001b[0m | \u001b[0m0.9611   \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m0.908    \u001b[0m | \u001b[0m2.527    \u001b[0m | \u001b[0m0.8282   \u001b[0m | \u001b[0m0.04665  \u001b[0m | \u001b[0m7.774    \u001b[0m | \u001b[0m0.08213  \u001b[0m | \u001b[0m8.331    \u001b[0m | \u001b[0m3.808    \u001b[0m | \u001b[0m0.9844   \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m0.906    \u001b[0m | \u001b[0m2.364    \u001b[0m | \u001b[0m0.8367   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m7.599    \u001b[0m | \u001b[0m0.0881   \u001b[0m | \u001b[0m7.925    \u001b[0m | \u001b[0m3.456    \u001b[0m | \u001b[0m0.9496   \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m0.878    \u001b[0m | \u001b[0m7.62     \u001b[0m | \u001b[0m0.8472   \u001b[0m | \u001b[0m2.12     \u001b[0m | \u001b[0m2.697    \u001b[0m | \u001b[0m0.05536  \u001b[0m | \u001b[0m9.57     \u001b[0m | \u001b[0m7.827    \u001b[0m | \u001b[0m0.5578   \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m0.882    \u001b[0m | \u001b[0m8.294    \u001b[0m | \u001b[0m0.5613   \u001b[0m | \u001b[0m3.984    \u001b[0m | \u001b[0m8.153    \u001b[0m | \u001b[0m0.1808   \u001b[0m | \u001b[0m4.532    \u001b[0m | \u001b[0m1.533    \u001b[0m | \u001b[0m0.991    \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m0.881    \u001b[0m | \u001b[0m6.325    \u001b[0m | \u001b[0m0.8286   \u001b[0m | \u001b[0m0.9557   \u001b[0m | \u001b[0m2.986    \u001b[0m | \u001b[0m0.2204   \u001b[0m | \u001b[0m7.908    \u001b[0m | \u001b[0m4.727    \u001b[0m | \u001b[0m0.5235   \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m0.874    \u001b[0m | \u001b[0m2.43     \u001b[0m | \u001b[0m0.3122   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m7.686    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m8.17     \u001b[0m | \u001b[0m3.689    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m0.881    \u001b[0m | \u001b[0m4.751    \u001b[0m | \u001b[0m0.7789   \u001b[0m | \u001b[0m1.257    \u001b[0m | \u001b[0m5.978    \u001b[0m | \u001b[0m0.02767  \u001b[0m | \u001b[0m3.286    \u001b[0m | \u001b[0m6.016    \u001b[0m | \u001b[0m0.6494   \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m0.892    \u001b[0m | \u001b[0m0.1216   \u001b[0m | \u001b[0m0.7601   \u001b[0m | \u001b[0m1.801    \u001b[0m | \u001b[0m7.175    \u001b[0m | \u001b[0m0.03524  \u001b[0m | \u001b[0m5.41     \u001b[0m | \u001b[0m5.755    \u001b[0m | \u001b[0m0.582    \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m0.89     \u001b[0m | \u001b[0m0.6845   \u001b[0m | \u001b[0m0.4405   \u001b[0m | \u001b[0m3.472    \u001b[0m | \u001b[0m4.369    \u001b[0m | \u001b[0m0.03307  \u001b[0m | \u001b[0m9.699    \u001b[0m | \u001b[0m8.933    \u001b[0m | \u001b[0m0.8857   \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m0.886    \u001b[0m | \u001b[0m1.864    \u001b[0m | \u001b[0m0.4302   \u001b[0m | \u001b[0m0.6433   \u001b[0m | \u001b[0m8.937    \u001b[0m | \u001b[0m0.03009  \u001b[0m | \u001b[0m8.67     \u001b[0m | \u001b[0m3.87     \u001b[0m | \u001b[0m0.8677   \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m0.905    \u001b[0m | \u001b[0m2.456    \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m0.008942 \u001b[0m | \u001b[0m7.597    \u001b[0m | \u001b[0m0.2205   \u001b[0m | \u001b[0m8.292    \u001b[0m | \u001b[0m3.548    \u001b[0m | \u001b[0m0.7957   \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m0.904    \u001b[0m | \u001b[0m2.727    \u001b[0m | \u001b[0m0.7776   \u001b[0m | \u001b[0m0.8428   \u001b[0m | \u001b[0m7.591    \u001b[0m | \u001b[0m0.1165   \u001b[0m | \u001b[0m9.731    \u001b[0m | \u001b[0m3.765    \u001b[0m | \u001b[0m0.791    \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m0.897    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m0.5235   \u001b[0m | \u001b[0m0.2974   \u001b[0m | \u001b[0m8.013    \u001b[0m | \u001b[0m0.2941   \u001b[0m | \u001b[0m9.474    \u001b[0m | \u001b[0m9.294    \u001b[0m | \u001b[0m0.6715   \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m0.905    \u001b[0m | \u001b[0m2.54     \u001b[0m | \u001b[0m0.6234   \u001b[0m | \u001b[0m0.03711  \u001b[0m | \u001b[0m7.045    \u001b[0m | \u001b[0m0.1275   \u001b[0m | \u001b[0m7.603    \u001b[0m | \u001b[0m2.131    \u001b[0m | \u001b[0m0.5501   \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m0.873    \u001b[0m | \u001b[0m6.511    \u001b[0m | \u001b[0m0.4252   \u001b[0m | \u001b[0m3.728    \u001b[0m | \u001b[0m8.458    \u001b[0m | \u001b[0m0.181    \u001b[0m | \u001b[0m3.183    \u001b[0m | \u001b[0m3.751    \u001b[0m | \u001b[0m0.9958   \u001b[0m |\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m0.904    \u001b[0m | \u001b[0m2.886    \u001b[0m | \u001b[0m0.591    \u001b[0m | \u001b[0m1.086    \u001b[0m | \u001b[0m7.354    \u001b[0m | \u001b[0m0.1423   \u001b[0m | \u001b[0m9.451    \u001b[0m | \u001b[0m3.45     \u001b[0m | \u001b[0m0.8314   \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m0.904    \u001b[0m | \u001b[0m1.863    \u001b[0m | \u001b[0m0.6685   \u001b[0m | \u001b[0m0.4187   \u001b[0m | \u001b[0m9.062    \u001b[0m | \u001b[0m0.2493   \u001b[0m | \u001b[0m7.498    \u001b[0m | \u001b[0m3.185    \u001b[0m | \u001b[0m0.6787   \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m0.878    \u001b[0m | \u001b[0m9.179    \u001b[0m | \u001b[0m0.6582   \u001b[0m | \u001b[0m0.1563   \u001b[0m | \u001b[0m6.57     \u001b[0m | \u001b[0m0.1022   \u001b[0m | \u001b[0m10.92    \u001b[0m | \u001b[0m2.111    \u001b[0m | \u001b[0m0.5009   \u001b[0m |\n",
      "=========================================================================================================================\n",
      "{'target': 0.909, 'params': {'alpha': 1.453486554830357, 'colsample_bytree': 0.7388798187238547, 'gamma': 0.0, 'lambda_': 6.615961350957569, 'learning_rate': 0.17798870950316995, 'max_depth': 7.847208291068528, 'min_child_weight': 4.236515605517397, 'subsample': 0.9448688245044577}}\n"
     ]
    }
   ],
   "source": [
    "# import xgboost as xgb\n",
    "# from bayes_opt import BayesianOptimization\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# # DÃ©finir la fonction Ã  optimiser\n",
    "# def xgb_evaluate(max_depth, min_child_weight, gamma, subsample, colsample_bytree, \n",
    "#                  alpha, lambda_, learning_rate):\n",
    "#     params = {'eval_metric': 'logloss',\n",
    "#               'max_depth': int(max_depth),\n",
    "#               'min_child_weight': min_child_weight,\n",
    "#               'subsample': subsample,\n",
    "#               'gamma': gamma,\n",
    "#               'colsample_bytree': colsample_bytree,\n",
    "#               'alpha': alpha,\n",
    "#               'lambda': lambda_,\n",
    "#               'learning_rate': learning_rate,\n",
    "#               'use_label_encoder': False,\n",
    "#               'objective': 'binary:logistic',\n",
    "#               'seed': 42}\n",
    "#     # Le modÃ¨le XGBClassifier est crÃ©Ã© avec les paramÃ¨tres sÃ©lectionnÃ©s\n",
    "#     clf = xgb.XGBClassifier(**params)\n",
    "#     # Calcul de la prÃ©cision en utilisant la validation croisÃ©e\n",
    "#     scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "#     return scores.mean()\n",
    "\n",
    "# # DÃ©finir les bornes des paramÃ¨tres Ã  optimiser\n",
    "# param_bounds = {\n",
    "#     'max_depth': (3, 12),\n",
    "#     'min_child_weight': (0, 10),\n",
    "#     'gamma': (0, 5),\n",
    "#     'subsample': (0.5, 1.0),\n",
    "#     'colsample_bytree': (0.3, 0.9),\n",
    "#     'alpha': (0, 10),\n",
    "#     'lambda_': (1, 10),\n",
    "#     'learning_rate': (0.01, 0.3)\n",
    "# }\n",
    "\n",
    "# # Utiliser BayesianOptimization pour optimiser les hyperparamÃ¨tres\n",
    "# optimizer = BayesianOptimization(\n",
    "#     f=xgb_evaluate,\n",
    "#     pbounds=param_bounds,\n",
    "#     random_state=42,\n",
    "# )\n",
    "\n",
    "# # DÃ©marrer l'optimisation\n",
    "# optimizer.maximize(init_points=10, n_iter=600)\n",
    "\n",
    "# # Afficher les meilleurs paramÃ¨tres\n",
    "# print(optimizer.max)\n",
    "\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and y are your features and labels\n",
    "# Replace these with your actual data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Define the function to optimize\n",
    "def xgb_evaluate(max_depth, min_child_weight, gamma, subsample, colsample_bytree, \n",
    "                 alpha, lambda_, learning_rate):\n",
    "    params = {'eval_metric': 'logloss',\n",
    "              'max_depth': int(max_depth),\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'subsample': subsample,\n",
    "              'gamma': gamma,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'alpha': alpha,\n",
    "              'lambda': lambda_,\n",
    "              'learning_rate': learning_rate,\n",
    "              'use_label_encoder': False,\n",
    "              'objective': 'binary:logistic',\n",
    "              'seed': 42}\n",
    "    clf = xgb.XGBClassifier(**params)\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "# Define the bounds for hyperparameters\n",
    "param_bounds = {\n",
    "    'max_depth': (3, 12),\n",
    "    'min_child_weight': (0, 10),\n",
    "    'gamma': (0, 5),\n",
    "    'subsample': (0.5, 1.0),\n",
    "    'colsample_bytree': (0.3, 0.9),\n",
    "    'alpha': (0, 10),\n",
    "    'lambda_': (1, 10),\n",
    "    'learning_rate': (0.01, 0.3)\n",
    "}\n",
    "\n",
    "# Use BayesianOptimization for hyperparameter optimization\n",
    "optimizer = BayesianOptimization(\n",
    "    f=xgb_evaluate,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Start the optimization with a reduced number of iterations\n",
    "# Adjust the 'n_iter' value based on your desired runtime\n",
    "optimizer.maximize(init_points=10, n_iter=50)\n",
    "\n",
    "# Display the best hyperparameter values\n",
    "print(optimizer.max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   | colsam... |   gamma   |  lambda_  | learni... | max_depth | min_ch... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.889    \u001b[0m | \u001b[0m3.745    \u001b[0m | \u001b[0m0.8704   \u001b[0m | \u001b[0m3.66     \u001b[0m | \u001b[0m6.388    \u001b[0m | \u001b[0m0.05525  \u001b[0m | \u001b[0m4.404    \u001b[0m | \u001b[0m0.5808   \u001b[0m | \u001b[0m0.9331   \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.89     \u001b[0m | \u001b[95m6.011    \u001b[0m | \u001b[95m0.7248   \u001b[0m | \u001b[95m0.1029   \u001b[0m | \u001b[95m9.729    \u001b[0m | \u001b[95m0.2514   \u001b[0m | \u001b[95m4.911    \u001b[0m | \u001b[95m1.818    \u001b[0m | \u001b[95m0.5917   \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.894    \u001b[0m | \u001b[95m3.042    \u001b[0m | \u001b[95m0.6149   \u001b[0m | \u001b[95m2.16     \u001b[0m | \u001b[95m3.621    \u001b[0m | \u001b[95m0.1874   \u001b[0m | \u001b[95m4.255    \u001b[0m | \u001b[95m2.921    \u001b[0m | \u001b[95m0.6832   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.892    \u001b[0m | \u001b[0m4.561    \u001b[0m | \u001b[0m0.7711   \u001b[0m | \u001b[0m0.9984   \u001b[0m | \u001b[0m5.628    \u001b[0m | \u001b[0m0.1818   \u001b[0m | \u001b[0m3.418    \u001b[0m | \u001b[0m6.075    \u001b[0m | \u001b[0m0.5853   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.888    \u001b[0m | \u001b[0m0.6505   \u001b[0m | \u001b[0m0.8693   \u001b[0m | \u001b[0m4.828    \u001b[0m | \u001b[0m8.276    \u001b[0m | \u001b[0m0.09834  \u001b[0m | \u001b[0m3.879    \u001b[0m | \u001b[0m6.842    \u001b[0m | \u001b[0m0.7201   \u001b[0m |\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m0.9      \u001b[0m | \u001b[95m1.22     \u001b[0m | \u001b[95m0.5971   \u001b[0m | \u001b[95m0.1719   \u001b[0m | \u001b[95m9.184    \u001b[0m | \u001b[95m0.08505  \u001b[0m | \u001b[95m8.963    \u001b[0m | \u001b[95m3.117    \u001b[0m | \u001b[95m0.76     \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.88     \u001b[0m | \u001b[0m5.467    \u001b[0m | \u001b[0m0.4109   \u001b[0m | \u001b[0m4.848    \u001b[0m | \u001b[0m7.976    \u001b[0m | \u001b[0m0.2825   \u001b[0m | \u001b[0m11.05    \u001b[0m | \u001b[0m5.979    \u001b[0m | \u001b[0m0.9609   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.894    \u001b[0m | \u001b[0m0.8849   \u001b[0m | \u001b[0m0.4176   \u001b[0m | \u001b[0m0.2261   \u001b[0m | \u001b[0m3.928    \u001b[0m | \u001b[0m0.1227   \u001b[0m | \u001b[0m5.442    \u001b[0m | \u001b[0m8.287    \u001b[0m | \u001b[0m0.6784   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.885    \u001b[0m | \u001b[0m2.809    \u001b[0m | \u001b[0m0.6256   \u001b[0m | \u001b[0m0.7046   \u001b[0m | \u001b[0m8.22     \u001b[0m | \u001b[0m0.03162  \u001b[0m | \u001b[0m11.88    \u001b[0m | \u001b[0m7.722    \u001b[0m | \u001b[0m0.5994   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.889    \u001b[0m | \u001b[0m0.05522  \u001b[0m | \u001b[0m0.7893   \u001b[0m | \u001b[0m3.534    \u001b[0m | \u001b[0m7.561    \u001b[0m | \u001b[0m0.2337   \u001b[0m | \u001b[0m3.666    \u001b[0m | \u001b[0m3.585    \u001b[0m | \u001b[0m0.5579   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.878    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4793   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m9.412    \u001b[0m | \u001b[0m0.01217  \u001b[0m | \u001b[0m8.912    \u001b[0m | \u001b[0m1.166    \u001b[0m | \u001b[0m0.7647   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.88     \u001b[0m | \u001b[0m5.009    \u001b[0m | \u001b[0m0.8238   \u001b[0m | \u001b[0m4.495    \u001b[0m | \u001b[0m1.717    \u001b[0m | \u001b[0m0.2515   \u001b[0m | \u001b[0m7.793    \u001b[0m | \u001b[0m6.433    \u001b[0m | \u001b[0m0.5576   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.899    \u001b[0m | \u001b[0m1.363    \u001b[0m | \u001b[0m0.7042   \u001b[0m | \u001b[0m2.556    \u001b[0m | \u001b[0m1.236    \u001b[0m | \u001b[0m0.0261   \u001b[0m | \u001b[0m5.232    \u001b[0m | \u001b[0m9.713    \u001b[0m | \u001b[0m0.8948   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.895    \u001b[0m | \u001b[0m5.481    \u001b[0m | \u001b[0m0.8474   \u001b[0m | \u001b[0m0.4227   \u001b[0m | \u001b[0m5.043    \u001b[0m | \u001b[0m0.06762  \u001b[0m | \u001b[0m8.316    \u001b[0m | \u001b[0m3.886    \u001b[0m | \u001b[0m0.8115   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.895    \u001b[0m | \u001b[0m2.615    \u001b[0m | \u001b[0m0.792    \u001b[0m | \u001b[0m4.897    \u001b[0m | \u001b[0m2.361    \u001b[0m | \u001b[0m0.2546   \u001b[0m | \u001b[0m9.728    \u001b[0m | \u001b[0m6.517    \u001b[0m | \u001b[0m0.9533   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.878    \u001b[0m | \u001b[0m6.368    \u001b[0m | \u001b[0m0.5681   \u001b[0m | \u001b[0m3.337    \u001b[0m | \u001b[0m7.332    \u001b[0m | \u001b[0m0.2578   \u001b[0m | \u001b[0m8.765    \u001b[0m | \u001b[0m7.395    \u001b[0m | \u001b[0m0.7385   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.893    \u001b[0m | \u001b[0m6.722    \u001b[0m | \u001b[0m0.7654   \u001b[0m | \u001b[0m0.8126   \u001b[0m | \u001b[0m2.162    \u001b[0m | \u001b[0m0.11     \u001b[0m | \u001b[0m3.256    \u001b[0m | \u001b[0m1.191    \u001b[0m | \u001b[0m0.9752   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.877    \u001b[0m | \u001b[0m7.579    \u001b[0m | \u001b[0m0.8808   \u001b[0m | \u001b[0m4.85     \u001b[0m | \u001b[0m7.653    \u001b[0m | \u001b[0m0.2432   \u001b[0m | \u001b[0m9.577    \u001b[0m | \u001b[0m6.768    \u001b[0m | \u001b[0m0.9525   \u001b[0m |\n",
      "| \u001b[95m19       \u001b[0m | \u001b[95m0.902    \u001b[0m | \u001b[95m1.907    \u001b[0m | \u001b[95m0.6678   \u001b[0m | \u001b[95m0.238    \u001b[0m | \u001b[95m9.011    \u001b[0m | \u001b[95m0.1256   \u001b[0m | \u001b[95m8.9      \u001b[0m | \u001b[95m4.093    \u001b[0m | \u001b[95m0.76     \u001b[0m |\n",
      "| \u001b[95m20       \u001b[0m | \u001b[95m0.908    \u001b[0m | \u001b[95m2.467    \u001b[0m | \u001b[95m0.6778   \u001b[0m | \u001b[95m0.02254  \u001b[0m | \u001b[95m7.52     \u001b[0m | \u001b[95m0.07577  \u001b[0m | \u001b[95m8.457    \u001b[0m | \u001b[95m3.353    \u001b[0m | \u001b[95m0.7742   \u001b[0m |\n",
      "| \u001b[95m21       \u001b[0m | \u001b[95m0.909    \u001b[0m | \u001b[95m1.453    \u001b[0m | \u001b[95m0.7389   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m6.616    \u001b[0m | \u001b[95m0.178    \u001b[0m | \u001b[95m7.847    \u001b[0m | \u001b[95m4.237    \u001b[0m | \u001b[95m0.9449   \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.885    \u001b[0m | \u001b[0m1.626    \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m5.623    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m9.545    \u001b[0m | \u001b[0m3.632    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.899    \u001b[0m | \u001b[0m1.998    \u001b[0m | \u001b[0m0.5677   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m7.71     \u001b[0m | \u001b[0m0.2215   \u001b[0m | \u001b[0m7.044    \u001b[0m | \u001b[0m3.942    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.895    \u001b[0m | \u001b[0m1.485    \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m0.8287   \u001b[0m | \u001b[0m7.457    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m8.374    \u001b[0m | \u001b[0m3.976    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.888    \u001b[0m | \u001b[0m2.861    \u001b[0m | \u001b[0m0.3      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m8.477    \u001b[0m | \u001b[0m0.3      \u001b[0m | \u001b[0m8.645    \u001b[0m | \u001b[0m3.126    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.905    \u001b[0m | \u001b[0m2.224    \u001b[0m | \u001b[0m0.6489   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m6.846    \u001b[0m | \u001b[0m0.1639   \u001b[0m | \u001b[0m7.991    \u001b[0m | \u001b[0m3.781    \u001b[0m | \u001b[0m0.859    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.879    \u001b[0m | \u001b[0m1.412    \u001b[0m | \u001b[0m0.3393   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m7.162    \u001b[0m | \u001b[0m0.3      \u001b[0m | \u001b[0m8.005    \u001b[0m | \u001b[0m3.766    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.874    \u001b[0m | \u001b[0m7.448    \u001b[0m | \u001b[0m0.4549   \u001b[0m | \u001b[0m1.164    \u001b[0m | \u001b[0m9.506    \u001b[0m | \u001b[0m0.01664  \u001b[0m | \u001b[0m8.245    \u001b[0m | \u001b[0m6.478    \u001b[0m | \u001b[0m0.9433   \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.888    \u001b[0m | \u001b[0m4.184    \u001b[0m | \u001b[0m0.5103   \u001b[0m | \u001b[0m2.765    \u001b[0m | \u001b[0m4.995    \u001b[0m | \u001b[0m0.1881   \u001b[0m | \u001b[0m4.064    \u001b[0m | \u001b[0m3.205    \u001b[0m | \u001b[0m0.9175   \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.871    \u001b[0m | \u001b[0m7.744    \u001b[0m | \u001b[0m0.535    \u001b[0m | \u001b[0m4.124    \u001b[0m | \u001b[0m7.347    \u001b[0m | \u001b[0m0.03209  \u001b[0m | \u001b[0m11.54    \u001b[0m | \u001b[0m6.735    \u001b[0m | \u001b[0m0.673    \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m0.901    \u001b[0m | \u001b[0m2.321    \u001b[0m | \u001b[0m0.5053   \u001b[0m | \u001b[0m0.2923   \u001b[0m | \u001b[0m7.085    \u001b[0m | \u001b[0m0.07914  \u001b[0m | \u001b[0m7.443    \u001b[0m | \u001b[0m3.933    \u001b[0m | \u001b[0m0.7342   \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.899    \u001b[0m | \u001b[0m2.619    \u001b[0m | \u001b[0m0.8806   \u001b[0m | \u001b[0m0.1582   \u001b[0m | \u001b[0m6.912    \u001b[0m | \u001b[0m0.1261   \u001b[0m | \u001b[0m8.038    \u001b[0m | \u001b[0m2.571    \u001b[0m | \u001b[0m0.5387   \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m0.897    \u001b[0m | \u001b[0m2.467    \u001b[0m | \u001b[0m0.7007   \u001b[0m | \u001b[0m0.3391   \u001b[0m | \u001b[0m6.276    \u001b[0m | \u001b[0m0.279    \u001b[0m | \u001b[0m7.876    \u001b[0m | \u001b[0m3.961    \u001b[0m | \u001b[0m0.8149   \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.906    \u001b[0m | \u001b[0m2.913    \u001b[0m | \u001b[0m0.5626   \u001b[0m | \u001b[0m0.6731   \u001b[0m | \u001b[0m7.612    \u001b[0m | \u001b[0m0.08811  \u001b[0m | \u001b[0m9.277    \u001b[0m | \u001b[0m3.751    \u001b[0m | \u001b[0m0.7584   \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.893    \u001b[0m | \u001b[0m2.719    \u001b[0m | \u001b[0m0.8934   \u001b[0m | \u001b[0m0.3135   \u001b[0m | \u001b[0m7.328    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m8.559    \u001b[0m | \u001b[0m3.849    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m0.905    \u001b[0m | \u001b[0m1.889    \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m6.708    \u001b[0m | \u001b[0m0.03345  \u001b[0m | \u001b[0m7.643    \u001b[0m | \u001b[0m4.225    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m0.894    \u001b[0m | \u001b[0m2.587    \u001b[0m | \u001b[0m0.4447   \u001b[0m | \u001b[0m0.3554   \u001b[0m | \u001b[0m7.645    \u001b[0m | \u001b[0m0.1765   \u001b[0m | \u001b[0m9.799    \u001b[0m | \u001b[0m3.569    \u001b[0m | \u001b[0m0.5808   \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.899    \u001b[0m | \u001b[0m2.24     \u001b[0m | \u001b[0m0.495    \u001b[0m | \u001b[0m0.113    \u001b[0m | \u001b[0m6.488    \u001b[0m | \u001b[0m0.1248   \u001b[0m | \u001b[0m8.264    \u001b[0m | \u001b[0m3.905    \u001b[0m | \u001b[0m0.727    \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.876    \u001b[0m | \u001b[0m8.584    \u001b[0m | \u001b[0m0.3152   \u001b[0m | \u001b[0m1.515    \u001b[0m | \u001b[0m5.982    \u001b[0m | \u001b[0m0.1412   \u001b[0m | \u001b[0m11.07    \u001b[0m | \u001b[0m5.772    \u001b[0m | \u001b[0m0.7155   \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m0.891    \u001b[0m | \u001b[0m2.616    \u001b[0m | \u001b[0m0.4614   \u001b[0m | \u001b[0m0.4754   \u001b[0m | \u001b[0m7.363    \u001b[0m | \u001b[0m0.05934  \u001b[0m | \u001b[0m8.739    \u001b[0m | \u001b[0m3.135    \u001b[0m | \u001b[0m0.6518   \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m0.884    \u001b[0m | \u001b[0m2.36     \u001b[0m | \u001b[0m0.7197   \u001b[0m | \u001b[0m0.8444   \u001b[0m | \u001b[0m8.46     \u001b[0m | \u001b[0m0.01159  \u001b[0m | \u001b[0m8.868    \u001b[0m | \u001b[0m4.22     \u001b[0m | \u001b[0m0.8799   \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m0.906    \u001b[0m | \u001b[0m1.686    \u001b[0m | \u001b[0m0.8215   \u001b[0m | \u001b[0m0.4194   \u001b[0m | \u001b[0m9.087    \u001b[0m | \u001b[0m0.09547  \u001b[0m | \u001b[0m8.007    \u001b[0m | \u001b[0m3.619    \u001b[0m | \u001b[0m0.9611   \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m0.908    \u001b[0m | \u001b[0m2.527    \u001b[0m | \u001b[0m0.8282   \u001b[0m | \u001b[0m0.04665  \u001b[0m | \u001b[0m7.774    \u001b[0m | \u001b[0m0.08213  \u001b[0m | \u001b[0m8.331    \u001b[0m | \u001b[0m3.808    \u001b[0m | \u001b[0m0.9844   \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m0.906    \u001b[0m | \u001b[0m2.364    \u001b[0m | \u001b[0m0.8367   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m7.599    \u001b[0m | \u001b[0m0.0881   \u001b[0m | \u001b[0m7.925    \u001b[0m | \u001b[0m3.456    \u001b[0m | \u001b[0m0.9496   \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m0.878    \u001b[0m | \u001b[0m7.62     \u001b[0m | \u001b[0m0.8472   \u001b[0m | \u001b[0m2.12     \u001b[0m | \u001b[0m2.697    \u001b[0m | \u001b[0m0.05536  \u001b[0m | \u001b[0m9.57     \u001b[0m | \u001b[0m7.827    \u001b[0m | \u001b[0m0.5578   \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m0.882    \u001b[0m | \u001b[0m8.294    \u001b[0m | \u001b[0m0.5613   \u001b[0m | \u001b[0m3.984    \u001b[0m | \u001b[0m8.153    \u001b[0m | \u001b[0m0.1808   \u001b[0m | \u001b[0m4.532    \u001b[0m | \u001b[0m1.533    \u001b[0m | \u001b[0m0.991    \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m0.881    \u001b[0m | \u001b[0m6.325    \u001b[0m | \u001b[0m0.8286   \u001b[0m | \u001b[0m0.9557   \u001b[0m | \u001b[0m2.986    \u001b[0m | \u001b[0m0.2204   \u001b[0m | \u001b[0m7.908    \u001b[0m | \u001b[0m4.727    \u001b[0m | \u001b[0m0.5235   \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m0.874    \u001b[0m | \u001b[0m2.43     \u001b[0m | \u001b[0m0.3122   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m7.686    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m8.17     \u001b[0m | \u001b[0m3.689    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m0.881    \u001b[0m | \u001b[0m4.751    \u001b[0m | \u001b[0m0.7789   \u001b[0m | \u001b[0m1.257    \u001b[0m | \u001b[0m5.978    \u001b[0m | \u001b[0m0.02767  \u001b[0m | \u001b[0m3.286    \u001b[0m | \u001b[0m6.016    \u001b[0m | \u001b[0m0.6494   \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m0.892    \u001b[0m | \u001b[0m0.1216   \u001b[0m | \u001b[0m0.7601   \u001b[0m | \u001b[0m1.801    \u001b[0m | \u001b[0m7.175    \u001b[0m | \u001b[0m0.03524  \u001b[0m | \u001b[0m5.41     \u001b[0m | \u001b[0m5.755    \u001b[0m | \u001b[0m0.582    \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m0.89     \u001b[0m | \u001b[0m0.6845   \u001b[0m | \u001b[0m0.4405   \u001b[0m | \u001b[0m3.472    \u001b[0m | \u001b[0m4.369    \u001b[0m | \u001b[0m0.03307  \u001b[0m | \u001b[0m9.699    \u001b[0m | \u001b[0m8.933    \u001b[0m | \u001b[0m0.8857   \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m0.886    \u001b[0m | \u001b[0m1.864    \u001b[0m | \u001b[0m0.4302   \u001b[0m | \u001b[0m0.6433   \u001b[0m | \u001b[0m8.937    \u001b[0m | \u001b[0m0.03009  \u001b[0m | \u001b[0m8.67     \u001b[0m | \u001b[0m3.87     \u001b[0m | \u001b[0m0.8677   \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m0.905    \u001b[0m | \u001b[0m2.456    \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m0.008942 \u001b[0m | \u001b[0m7.597    \u001b[0m | \u001b[0m0.2205   \u001b[0m | \u001b[0m8.292    \u001b[0m | \u001b[0m3.548    \u001b[0m | \u001b[0m0.7957   \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m0.904    \u001b[0m | \u001b[0m2.727    \u001b[0m | \u001b[0m0.7776   \u001b[0m | \u001b[0m0.8428   \u001b[0m | \u001b[0m7.591    \u001b[0m | \u001b[0m0.1165   \u001b[0m | \u001b[0m9.731    \u001b[0m | \u001b[0m3.765    \u001b[0m | \u001b[0m0.791    \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m0.897    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m0.5235   \u001b[0m | \u001b[0m0.2974   \u001b[0m | \u001b[0m8.013    \u001b[0m | \u001b[0m0.2941   \u001b[0m | \u001b[0m9.474    \u001b[0m | \u001b[0m9.294    \u001b[0m | \u001b[0m0.6715   \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m0.905    \u001b[0m | \u001b[0m2.54     \u001b[0m | \u001b[0m0.6234   \u001b[0m | \u001b[0m0.03711  \u001b[0m | \u001b[0m7.045    \u001b[0m | \u001b[0m0.1275   \u001b[0m | \u001b[0m7.603    \u001b[0m | \u001b[0m2.131    \u001b[0m | \u001b[0m0.5501   \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m0.873    \u001b[0m | \u001b[0m6.511    \u001b[0m | \u001b[0m0.4252   \u001b[0m | \u001b[0m3.728    \u001b[0m | \u001b[0m8.458    \u001b[0m | \u001b[0m0.181    \u001b[0m | \u001b[0m3.183    \u001b[0m | \u001b[0m3.751    \u001b[0m | \u001b[0m0.9958   \u001b[0m |\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m0.904    \u001b[0m | \u001b[0m2.886    \u001b[0m | \u001b[0m0.591    \u001b[0m | \u001b[0m1.086    \u001b[0m | \u001b[0m7.354    \u001b[0m | \u001b[0m0.1423   \u001b[0m | \u001b[0m9.451    \u001b[0m | \u001b[0m3.45     \u001b[0m | \u001b[0m0.8314   \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m0.904    \u001b[0m | \u001b[0m1.863    \u001b[0m | \u001b[0m0.6685   \u001b[0m | \u001b[0m0.4187   \u001b[0m | \u001b[0m9.062    \u001b[0m | \u001b[0m0.2493   \u001b[0m | \u001b[0m7.498    \u001b[0m | \u001b[0m3.185    \u001b[0m | \u001b[0m0.6787   \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m0.878    \u001b[0m | \u001b[0m9.179    \u001b[0m | \u001b[0m0.6582   \u001b[0m | \u001b[0m0.1563   \u001b[0m | \u001b[0m6.57     \u001b[0m | \u001b[0m0.1022   \u001b[0m | \u001b[0m10.92    \u001b[0m | \u001b[0m2.111    \u001b[0m | \u001b[0m0.5009   \u001b[0m |\n",
      "=========================================================================================================================\n",
      "{'target': 0.909, 'params': {'alpha': 1.453486554830357, 'colsample_bytree': 0.7388798187238547, 'gamma': 0.0, 'lambda_': 6.615961350957569, 'learning_rate': 0.17798870950316995, 'max_depth': 7.847208291068528, 'min_child_weight': 4.236515605517397, 'subsample': 0.9448688245044577}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning:\n",
      "\n",
      "[10:03:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"lambda_\" } are not used.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(alpha=1.453486554830357, base_score=None, booster=None,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7388798187238547, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              lambda_=6.615961350957569, learning_rate=0.17798870950316995,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=4.236515605517397, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(alpha=1.453486554830357, base_score=None, booster=None,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7388798187238547, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              lambda_=6.615961350957569, learning_rate=0.17798870950316995,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=4.236515605517397, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(alpha=1.453486554830357, base_score=None, booster=None,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7388798187238547, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              lambda_=6.615961350957569, learning_rate=0.17798870950316995,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=4.236515605517397, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, ...)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and y are your features and labels\n",
    "# Replace these with your actual data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Define the function to optimize\n",
    "def xgb_evaluate(max_depth, min_child_weight, gamma, subsample, colsample_bytree, \n",
    "                 alpha, lambda_, learning_rate):\n",
    "    params = {'eval_metric': 'logloss',\n",
    "              'max_depth': int(max_depth),\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'subsample': subsample,\n",
    "              'gamma': gamma,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'alpha': alpha,\n",
    "              'lambda': lambda_,\n",
    "              'learning_rate': learning_rate,\n",
    "              'use_label_encoder': False,\n",
    "              'objective': 'binary:logistic',\n",
    "              'seed': 42}\n",
    "    clf = xgb.XGBClassifier(**params)\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "# Define the bounds for hyperparameters\n",
    "param_bounds = {\n",
    "    'max_depth': (3, 12),\n",
    "    'min_child_weight': (0, 10),\n",
    "    'gamma': (0, 5),\n",
    "    'subsample': (0.5, 1.0),\n",
    "    'colsample_bytree': (0.3, 0.9),\n",
    "    'alpha': (0, 10),\n",
    "    'lambda_': (1, 10),\n",
    "    'learning_rate': (0.01, 0.3)\n",
    "}\n",
    "\n",
    "# Use BayesianOptimization for hyperparameter optimization\n",
    "optimizer = BayesianOptimization(\n",
    "    f=xgb_evaluate,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Start the optimization with a reduced number of iterations\n",
    "# Adjust the 'n_iter' value based on your desired runtime\n",
    "optimizer.maximize(init_points=10, n_iter=50)\n",
    "\n",
    "# Display the best hyperparameter values\n",
    "print(optimizer.max)\n",
    "\n",
    "# Assuming 'params' is defined with the best hyperparameters\n",
    "params = optimizer.max['params']\n",
    "\n",
    "# Convert 'max_depth' to integer\n",
    "params['max_depth'] = int(params['max_depth'])\n",
    "\n",
    "# Training XGBoost model\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   | colsam... |   gamma   |  lambda_  | learni... | max_depth | min_ch... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.8863   \u001b[0m | \u001b[0m3.745    \u001b[0m | \u001b[0m0.8704   \u001b[0m | \u001b[0m3.66     \u001b[0m | \u001b[0m6.388    \u001b[0m | \u001b[0m0.05525  \u001b[0m | \u001b[0m4.404    \u001b[0m | \u001b[0m0.5808   \u001b[0m | \u001b[0m0.9331   \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.8838   \u001b[0m | \u001b[0m6.011    \u001b[0m | \u001b[0m0.7248   \u001b[0m | \u001b[0m0.1029   \u001b[0m | \u001b[0m9.729    \u001b[0m | \u001b[0m0.2514   \u001b[0m | \u001b[0m4.911    \u001b[0m | \u001b[0m1.818    \u001b[0m | \u001b[0m0.5917   \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.8975   \u001b[0m | \u001b[95m3.042    \u001b[0m | \u001b[95m0.6149   \u001b[0m | \u001b[95m2.16     \u001b[0m | \u001b[95m3.621    \u001b[0m | \u001b[95m0.1874   \u001b[0m | \u001b[95m4.255    \u001b[0m | \u001b[95m2.921    \u001b[0m | \u001b[95m0.6832   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.88     \u001b[0m | \u001b[0m4.561    \u001b[0m | \u001b[0m0.7711   \u001b[0m | \u001b[0m0.9984   \u001b[0m | \u001b[0m5.628    \u001b[0m | \u001b[0m0.1818   \u001b[0m | \u001b[0m3.418    \u001b[0m | \u001b[0m6.075    \u001b[0m | \u001b[0m0.5853   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.885    \u001b[0m | \u001b[0m0.6505   \u001b[0m | \u001b[0m0.8693   \u001b[0m | \u001b[0m4.828    \u001b[0m | \u001b[0m8.276    \u001b[0m | \u001b[0m0.09834  \u001b[0m | \u001b[0m3.879    \u001b[0m | \u001b[0m6.842    \u001b[0m | \u001b[0m0.7201   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.8938   \u001b[0m | \u001b[0m1.22     \u001b[0m | \u001b[0m0.5971   \u001b[0m | \u001b[0m0.1719   \u001b[0m | \u001b[0m9.184    \u001b[0m | \u001b[0m0.08505  \u001b[0m | \u001b[0m8.963    \u001b[0m | \u001b[0m3.117    \u001b[0m | \u001b[0m0.76     \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.87     \u001b[0m | \u001b[0m5.467    \u001b[0m | \u001b[0m0.4109   \u001b[0m | \u001b[0m4.848    \u001b[0m | \u001b[0m7.976    \u001b[0m | \u001b[0m0.2825   \u001b[0m | \u001b[0m11.05    \u001b[0m | \u001b[0m5.979    \u001b[0m | \u001b[0m0.9609   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.885    \u001b[0m | \u001b[0m0.8849   \u001b[0m | \u001b[0m0.4176   \u001b[0m | \u001b[0m0.2261   \u001b[0m | \u001b[0m3.928    \u001b[0m | \u001b[0m0.1227   \u001b[0m | \u001b[0m5.442    \u001b[0m | \u001b[0m8.287    \u001b[0m | \u001b[0m0.6784   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.88     \u001b[0m | \u001b[0m2.809    \u001b[0m | \u001b[0m0.6256   \u001b[0m | \u001b[0m0.7046   \u001b[0m | \u001b[0m8.22     \u001b[0m | \u001b[0m0.03162  \u001b[0m | \u001b[0m11.88    \u001b[0m | \u001b[0m7.722    \u001b[0m | \u001b[0m0.5994   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.8888   \u001b[0m | \u001b[0m0.05522  \u001b[0m | \u001b[0m0.7893   \u001b[0m | \u001b[0m3.534    \u001b[0m | \u001b[0m7.561    \u001b[0m | \u001b[0m0.2337   \u001b[0m | \u001b[0m3.666    \u001b[0m | \u001b[0m3.585    \u001b[0m | \u001b[0m0.5579   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.8787   \u001b[0m | \u001b[0m1.313    \u001b[0m | \u001b[0m0.4858   \u001b[0m | \u001b[0m1.009    \u001b[0m | \u001b[0m9.179    \u001b[0m | \u001b[0m0.2305   \u001b[0m | \u001b[0m9.088    \u001b[0m | \u001b[0m3.01     \u001b[0m | \u001b[0m0.592    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.8838   \u001b[0m | \u001b[0m0.7926   \u001b[0m | \u001b[0m0.4221   \u001b[0m | \u001b[0m0.2646   \u001b[0m | \u001b[0m3.384    \u001b[0m | \u001b[0m0.2574   \u001b[0m | \u001b[0m5.362    \u001b[0m | \u001b[0m8.161    \u001b[0m | \u001b[0m0.6598   \u001b[0m |\n",
      "| \u001b[95m13       \u001b[0m | \u001b[95m0.9      \u001b[0m | \u001b[95m1.363    \u001b[0m | \u001b[95m0.7042   \u001b[0m | \u001b[95m2.556    \u001b[0m | \u001b[95m1.236    \u001b[0m | \u001b[95m0.0261   \u001b[0m | \u001b[95m5.232    \u001b[0m | \u001b[95m9.713    \u001b[0m | \u001b[95m0.8948   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.8962   \u001b[0m | \u001b[0m3.099    \u001b[0m | \u001b[0m0.8834   \u001b[0m | \u001b[0m2.22     \u001b[0m | \u001b[0m3.911    \u001b[0m | \u001b[0m0.1533   \u001b[0m | \u001b[0m4.368    \u001b[0m | \u001b[0m3.284    \u001b[0m | \u001b[0m0.7548   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.8913   \u001b[0m | \u001b[0m1.691    \u001b[0m | \u001b[0m0.6727   \u001b[0m | \u001b[0m2.859    \u001b[0m | \u001b[0m1.627    \u001b[0m | \u001b[0m0.1113   \u001b[0m | \u001b[0m6.01     \u001b[0m | \u001b[0m9.817    \u001b[0m | \u001b[0m0.7047   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.8863   \u001b[0m | \u001b[0m1.077    \u001b[0m | \u001b[0m0.5791   \u001b[0m | \u001b[0m2.302    \u001b[0m | \u001b[0m1.692    \u001b[0m | \u001b[0m0.07113  \u001b[0m | \u001b[0m4.754    \u001b[0m | \u001b[0m9.031    \u001b[0m | \u001b[0m0.7641   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.8763   \u001b[0m | \u001b[0m2.679    \u001b[0m | \u001b[0m0.3265   \u001b[0m | \u001b[0m2.57     \u001b[0m | \u001b[0m3.842    \u001b[0m | \u001b[0m0.03128  \u001b[0m | \u001b[0m4.861    \u001b[0m | \u001b[0m3.238    \u001b[0m | \u001b[0m0.9217   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.8812   \u001b[0m | \u001b[0m1.311    \u001b[0m | \u001b[0m0.4219   \u001b[0m | \u001b[0m2.365    \u001b[0m | \u001b[0m1.29     \u001b[0m | \u001b[0m0.1793   \u001b[0m | \u001b[0m5.747    \u001b[0m | \u001b[0m9.518    \u001b[0m | \u001b[0m0.6622   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.8862   \u001b[0m | \u001b[0m8.615    \u001b[0m | \u001b[0m0.7045   \u001b[0m | \u001b[0m0.3774   \u001b[0m | \u001b[0m5.665    \u001b[0m | \u001b[0m0.0884   \u001b[0m | \u001b[0m9.083    \u001b[0m | \u001b[0m4.846    \u001b[0m | \u001b[0m0.8102   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.8862   \u001b[0m | \u001b[0m1.351    \u001b[0m | \u001b[0m0.3169   \u001b[0m | \u001b[0m2.407    \u001b[0m | \u001b[0m7.52     \u001b[0m | \u001b[0m0.2719   \u001b[0m | \u001b[0m4.351    \u001b[0m | \u001b[0m8.274    \u001b[0m | \u001b[0m0.8302   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.875    \u001b[0m | \u001b[0m3.014    \u001b[0m | \u001b[0m0.3758   \u001b[0m | \u001b[0m2.391    \u001b[0m | \u001b[0m4.073    \u001b[0m | \u001b[0m0.03487  \u001b[0m | \u001b[0m3.93     \u001b[0m | \u001b[0m3.573    \u001b[0m | \u001b[0m0.9493   \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.8925   \u001b[0m | \u001b[0m2.965    \u001b[0m | \u001b[0m0.3354   \u001b[0m | \u001b[0m1.547    \u001b[0m | \u001b[0m4.131    \u001b[0m | \u001b[0m0.1974   \u001b[0m | \u001b[0m4.285    \u001b[0m | \u001b[0m2.805    \u001b[0m | \u001b[0m0.8138   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.86     \u001b[0m | \u001b[0m9.59     \u001b[0m | \u001b[0m0.3307   \u001b[0m | \u001b[0m3.143    \u001b[0m | \u001b[0m8.646    \u001b[0m | \u001b[0m0.02839  \u001b[0m | \u001b[0m6.899    \u001b[0m | \u001b[0m0.01175  \u001b[0m | \u001b[0m0.5259   \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.86     \u001b[0m | \u001b[0m7.863    \u001b[0m | \u001b[0m0.3823   \u001b[0m | \u001b[0m4.676    \u001b[0m | \u001b[0m3.892    \u001b[0m | \u001b[0m0.1833   \u001b[0m | \u001b[0m11.41    \u001b[0m | \u001b[0m2.255    \u001b[0m | \u001b[0m0.5115   \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.8675   \u001b[0m | \u001b[0m6.919    \u001b[0m | \u001b[0m0.4229   \u001b[0m | \u001b[0m3.635    \u001b[0m | \u001b[0m8.786    \u001b[0m | \u001b[0m0.03036  \u001b[0m | \u001b[0m3.866    \u001b[0m | \u001b[0m1.881    \u001b[0m | \u001b[0m0.8      \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.8862   \u001b[0m | \u001b[0m3.395    \u001b[0m | \u001b[0m0.8771   \u001b[0m | \u001b[0m2.735    \u001b[0m | \u001b[0m4.254    \u001b[0m | \u001b[0m0.04297  \u001b[0m | \u001b[0m4.112    \u001b[0m | \u001b[0m2.77     \u001b[0m | \u001b[0m0.5832   \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.875    \u001b[0m | \u001b[0m7.241    \u001b[0m | \u001b[0m0.4397   \u001b[0m | \u001b[0m0.6867   \u001b[0m | \u001b[0m2.23     \u001b[0m | \u001b[0m0.2355   \u001b[0m | \u001b[0m8.809    \u001b[0m | \u001b[0m2.427    \u001b[0m | \u001b[0m0.7527   \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.8675   \u001b[0m | \u001b[0m7.448    \u001b[0m | \u001b[0m0.4549   \u001b[0m | \u001b[0m1.164    \u001b[0m | \u001b[0m9.506    \u001b[0m | \u001b[0m0.01664  \u001b[0m | \u001b[0m8.245    \u001b[0m | \u001b[0m6.478    \u001b[0m | \u001b[0m0.9433   \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.8863   \u001b[0m | \u001b[0m4.184    \u001b[0m | \u001b[0m0.5103   \u001b[0m | \u001b[0m2.765    \u001b[0m | \u001b[0m4.995    \u001b[0m | \u001b[0m0.1881   \u001b[0m | \u001b[0m4.064    \u001b[0m | \u001b[0m3.205    \u001b[0m | \u001b[0m0.9175   \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.865    \u001b[0m | \u001b[0m7.744    \u001b[0m | \u001b[0m0.535    \u001b[0m | \u001b[0m4.124    \u001b[0m | \u001b[0m7.347    \u001b[0m | \u001b[0m0.03209  \u001b[0m | \u001b[0m11.54    \u001b[0m | \u001b[0m6.735    \u001b[0m | \u001b[0m0.673    \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m0.8962   \u001b[0m | \u001b[0m3.057    \u001b[0m | \u001b[0m0.7289   \u001b[0m | \u001b[0m2.011    \u001b[0m | \u001b[0m3.93     \u001b[0m | \u001b[0m0.2618   \u001b[0m | \u001b[0m3.972    \u001b[0m | \u001b[0m2.963    \u001b[0m | \u001b[0m0.9208   \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.8975   \u001b[0m | \u001b[0m1.611    \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m2.949    \u001b[0m | \u001b[0m1.441    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m5.082    \u001b[0m | \u001b[0m9.963    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m0.8875   \u001b[0m | \u001b[0m3.5      \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m1.669    \u001b[0m | \u001b[0m3.658    \u001b[0m | \u001b[0m0.3      \u001b[0m | \u001b[0m4.367    \u001b[0m | \u001b[0m2.956    \u001b[0m | \u001b[0m0.5972   \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.8987   \u001b[0m | \u001b[0m2.067    \u001b[0m | \u001b[0m0.5796   \u001b[0m | \u001b[0m2.525    \u001b[0m | \u001b[0m1.436    \u001b[0m | \u001b[0m0.1483   \u001b[0m | \u001b[0m4.968    \u001b[0m | \u001b[0m9.903    \u001b[0m | \u001b[0m0.7823   \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.8912   \u001b[0m | \u001b[0m2.513    \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m1.905    \u001b[0m | \u001b[0m3.832    \u001b[0m | \u001b[0m0.3      \u001b[0m | \u001b[0m4.181    \u001b[0m | \u001b[0m2.809    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m0.8863   \u001b[0m | \u001b[0m2.562    \u001b[0m | \u001b[0m0.4286   \u001b[0m | \u001b[0m2.856    \u001b[0m | \u001b[0m1.549    \u001b[0m | \u001b[0m0.1412   \u001b[0m | \u001b[0m4.735    \u001b[0m | \u001b[0m9.578    \u001b[0m | \u001b[0m0.8677   \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m0.8975   \u001b[0m | \u001b[0m1.635    \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m2.295    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m4.801    \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.8962   \u001b[0m | \u001b[0m1.614    \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m2.203    \u001b[0m | \u001b[0m1.769    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m5.136    \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.89     \u001b[0m | \u001b[0m2.973    \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m2.16     \u001b[0m | \u001b[0m3.172    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m3.897    \u001b[0m | \u001b[0m2.424    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m0.8938   \u001b[0m | \u001b[0m0.7712   \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m9.208    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m8.357    \u001b[0m | \u001b[0m3.641    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m0.8825   \u001b[0m | \u001b[0m0.1355   \u001b[0m | \u001b[0m0.4041   \u001b[0m | \u001b[0m0.1265   \u001b[0m | \u001b[0m9.433    \u001b[0m | \u001b[0m0.2195   \u001b[0m | \u001b[0m8.489    \u001b[0m | \u001b[0m2.241    \u001b[0m | \u001b[0m0.7737   \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m0.8975   \u001b[0m | \u001b[0m1.014    \u001b[0m | \u001b[0m0.7505   \u001b[0m | \u001b[0m3.119    \u001b[0m | \u001b[0m1.795    \u001b[0m | \u001b[0m0.2699   \u001b[0m | \u001b[0m4.591    \u001b[0m | \u001b[0m9.753    \u001b[0m | \u001b[0m0.6945   \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m0.865    \u001b[0m | \u001b[0m1.338    \u001b[0m | \u001b[0m0.4224   \u001b[0m | \u001b[0m2.735    \u001b[0m | \u001b[0m1.229    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m4.652    \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m0.8737   \u001b[0m | \u001b[0m1.794    \u001b[0m | \u001b[0m0.3739   \u001b[0m | \u001b[0m2.593    \u001b[0m | \u001b[0m1.343    \u001b[0m | \u001b[0m0.01649  \u001b[0m | \u001b[0m5.132    \u001b[0m | \u001b[0m9.464    \u001b[0m | \u001b[0m0.9275   \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m0.8738   \u001b[0m | \u001b[0m7.62     \u001b[0m | \u001b[0m0.8472   \u001b[0m | \u001b[0m2.12     \u001b[0m | \u001b[0m2.697    \u001b[0m | \u001b[0m0.05536  \u001b[0m | \u001b[0m9.57     \u001b[0m | \u001b[0m7.827    \u001b[0m | \u001b[0m0.5578   \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m0.8675   \u001b[0m | \u001b[0m8.294    \u001b[0m | \u001b[0m0.5613   \u001b[0m | \u001b[0m3.984    \u001b[0m | \u001b[0m8.153    \u001b[0m | \u001b[0m0.1808   \u001b[0m | \u001b[0m4.532    \u001b[0m | \u001b[0m1.533    \u001b[0m | \u001b[0m0.991    \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m0.8838   \u001b[0m | \u001b[0m6.325    \u001b[0m | \u001b[0m0.8286   \u001b[0m | \u001b[0m0.9557   \u001b[0m | \u001b[0m2.986    \u001b[0m | \u001b[0m0.2204   \u001b[0m | \u001b[0m7.908    \u001b[0m | \u001b[0m4.727    \u001b[0m | \u001b[0m0.5235   \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m0.885    \u001b[0m | \u001b[0m3.443    \u001b[0m | \u001b[0m0.6601   \u001b[0m | \u001b[0m1.712    \u001b[0m | \u001b[0m4.267    \u001b[0m | \u001b[0m0.01382  \u001b[0m | \u001b[0m4.321    \u001b[0m | \u001b[0m2.977    \u001b[0m | \u001b[0m0.9514   \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m0.8812   \u001b[0m | \u001b[0m4.307    \u001b[0m | \u001b[0m0.643    \u001b[0m | \u001b[0m2.797    \u001b[0m | \u001b[0m4.938    \u001b[0m | \u001b[0m0.1559   \u001b[0m | \u001b[0m3.962    \u001b[0m | \u001b[0m3.118    \u001b[0m | \u001b[0m0.6489   \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m0.8925   \u001b[0m | \u001b[0m0.1216   \u001b[0m | \u001b[0m0.7601   \u001b[0m | \u001b[0m1.801    \u001b[0m | \u001b[0m7.175    \u001b[0m | \u001b[0m0.03524  \u001b[0m | \u001b[0m5.41     \u001b[0m | \u001b[0m5.755    \u001b[0m | \u001b[0m0.582    \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m0.885    \u001b[0m | \u001b[0m0.6845   \u001b[0m | \u001b[0m0.4405   \u001b[0m | \u001b[0m3.472    \u001b[0m | \u001b[0m4.369    \u001b[0m | \u001b[0m0.03307  \u001b[0m | \u001b[0m9.699    \u001b[0m | \u001b[0m8.933    \u001b[0m | \u001b[0m0.8857   \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m0.8825   \u001b[0m | \u001b[0m6.223    \u001b[0m | \u001b[0m0.8349   \u001b[0m | \u001b[0m2.716    \u001b[0m | \u001b[0m2.19     \u001b[0m | \u001b[0m0.2492   \u001b[0m | \u001b[0m5.103    \u001b[0m | \u001b[0m8.372    \u001b[0m | \u001b[0m0.7494   \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m0.8975   \u001b[0m | \u001b[0m2.853    \u001b[0m | \u001b[0m0.7312   \u001b[0m | \u001b[0m1.427    \u001b[0m | \u001b[0m3.777    \u001b[0m | \u001b[0m0.1569   \u001b[0m | \u001b[0m4.259    \u001b[0m | \u001b[0m3.425    \u001b[0m | \u001b[0m0.7904   \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m0.87     \u001b[0m | \u001b[0m9.674    \u001b[0m | \u001b[0m0.655    \u001b[0m | \u001b[0m3.704    \u001b[0m | \u001b[0m2.453    \u001b[0m | \u001b[0m0.1134   \u001b[0m | \u001b[0m10.42    \u001b[0m | \u001b[0m2.265    \u001b[0m | \u001b[0m0.7119   \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m0.885    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m0.5235   \u001b[0m | \u001b[0m0.2974   \u001b[0m | \u001b[0m8.013    \u001b[0m | \u001b[0m0.2941   \u001b[0m | \u001b[0m9.474    \u001b[0m | \u001b[0m9.294    \u001b[0m | \u001b[0m0.6715   \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m0.8887   \u001b[0m | \u001b[0m2.423    \u001b[0m | \u001b[0m0.3765   \u001b[0m | \u001b[0m1.964    \u001b[0m | \u001b[0m3.206    \u001b[0m | \u001b[0m0.2411   \u001b[0m | \u001b[0m4.343    \u001b[0m | \u001b[0m3.336    \u001b[0m | \u001b[0m0.7603   \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m0.8762   \u001b[0m | \u001b[0m6.511    \u001b[0m | \u001b[0m0.4252   \u001b[0m | \u001b[0m3.728    \u001b[0m | \u001b[0m8.458    \u001b[0m | \u001b[0m0.181    \u001b[0m | \u001b[0m3.183    \u001b[0m | \u001b[0m3.751    \u001b[0m | \u001b[0m0.9958   \u001b[0m |\n",
      "| \u001b[95m58       \u001b[0m | \u001b[95m0.9025   \u001b[0m | \u001b[95m0.8789   \u001b[0m | \u001b[95m0.6852   \u001b[0m | \u001b[95m0.07235  \u001b[0m | \u001b[95m8.595    \u001b[0m | \u001b[95m0.1328   \u001b[0m | \u001b[95m8.347    \u001b[0m | \u001b[95m3.618    \u001b[0m | \u001b[95m0.9748   \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m0.8925   \u001b[0m | \u001b[0m1.432    \u001b[0m | \u001b[0m0.6182   \u001b[0m | \u001b[0m2.815    \u001b[0m | \u001b[0m2.381    \u001b[0m | \u001b[0m0.1025   \u001b[0m | \u001b[0m4.672    \u001b[0m | \u001b[0m9.473    \u001b[0m | \u001b[0m0.6714   \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m0.8737   \u001b[0m | \u001b[0m9.179    \u001b[0m | \u001b[0m0.6582   \u001b[0m | \u001b[0m0.1563   \u001b[0m | \u001b[0m6.57     \u001b[0m | \u001b[0m0.1022   \u001b[0m | \u001b[0m10.92    \u001b[0m | \u001b[0m2.111    \u001b[0m | \u001b[0m0.5009   \u001b[0m |\n",
      "=========================================================================================================================\n",
      "{'target': 0.9025000000000001, 'params': {'alpha': 0.8789177464741638, 'colsample_bytree': 0.6851726528563349, 'gamma': 0.07235465014777342, 'lambda_': 8.595145153425015, 'learning_rate': 0.1327585861390045, 'max_depth': 8.3474430424294, 'min_child_weight': 3.617924510579323, 'subsample': 0.9747829538192767}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning:\n",
      "\n",
      "[10:05:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"lambda_\" } are not used.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Assuming X and y are your features and labels\n",
    "# Replace these with your actual data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the function to optimize\n",
    "def xgb_evaluate(max_depth, min_child_weight, gamma, subsample, colsample_bytree, \n",
    "                 alpha, lambda_, learning_rate):\n",
    "    params = {'eval_metric': 'logloss',\n",
    "              'max_depth': int(max_depth),\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'subsample': subsample,\n",
    "              'gamma': gamma,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'alpha': alpha,\n",
    "              'lambda': lambda_,\n",
    "              'learning_rate': learning_rate,\n",
    "              'use_label_encoder': False,\n",
    "              'objective': 'binary:logistic',\n",
    "              'seed': 42}\n",
    "    clf = xgb.XGBClassifier(**params)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "# Define the bounds for hyperparameters\n",
    "param_bounds = {\n",
    "    'max_depth': (3, 12),\n",
    "    'min_child_weight': (0, 10),\n",
    "    'gamma': (0, 5),\n",
    "    'subsample': (0.5, 1.0),\n",
    "    'colsample_bytree': (0.3, 0.9),\n",
    "    'alpha': (0, 10),\n",
    "    'lambda_': (1, 10),\n",
    "    'learning_rate': (0.01, 0.3)\n",
    "}\n",
    "\n",
    "# Use BayesianOptimization for hyperparameter optimization\n",
    "optimizer = BayesianOptimization(\n",
    "    f=xgb_evaluate,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Start the optimization with a reduced number of iterations\n",
    "# Adjust the 'n_iter' value based on your desired runtime\n",
    "optimizer.maximize(init_points=10, n_iter=50)\n",
    "\n",
    "# Display the best hyperparameter values\n",
    "print(optimizer.max)\n",
    "\n",
    "# Assuming 'params' is defined with the best hyperparameters\n",
    "params = optimizer.max['params']\n",
    "params['max_depth'] = int(params['max_depth'])\n",
    "\n",
    "# Training XGBoost model\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pd.DataFrame(model.predict(X_test), columns=['NObeyesdad'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Columns: Index(['MTRANS_Automobile', 'MTRANS_Bike', 'MTRANS_Motorbike',\n",
      "       'MTRANS_Public_Transportation', 'MTRANS_Walking', 'CALC_Frequently',\n",
      "       'CALC_Sometimes', 'CALC_no', 'SCC_no', 'SCC_yes', 'SMOKE_no',\n",
      "       'SMOKE_yes', 'CAEC_Always', 'CAEC_Frequently', 'CAEC_Sometimes',\n",
      "       'CAEC_no', 'FAVC_no', 'FAVC_yes', 'family_history_with_overweight_no',\n",
      "       'family_history_with_overweight_yes', 'Gender_Female', 'Gender_Male',\n",
      "       'id', 'Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE',\n",
      "       'NObeyesdad'],\n",
      "      dtype='object')\n",
      "Test Set Columns: Index(['MTRANS_Automobile', 'MTRANS_Bike', 'MTRANS_Motorbike',\n",
      "       'MTRANS_Public_Transportation', 'MTRANS_Walking', 'CALC_Frequently',\n",
      "       'CALC_Sometimes', 'CALC_no', 'SCC_no', 'SCC_yes', 'SMOKE_no',\n",
      "       'SMOKE_yes', 'CAEC_Always', 'CAEC_Frequently', 'CAEC_Sometimes',\n",
      "       'CAEC_no', 'FAVC_no', 'FAVC_yes', 'family_history_with_overweight_no',\n",
      "       'family_history_with_overweight_yes', 'Gender_Female', 'Gender_Male',\n",
      "       'id', 'Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE'],\n",
      "      dtype='object')\n",
      "Number of Features in Training Set: 32\n",
      "Number of Features in Test Set: 31\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (800, 20), indices imply (800, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 23\u001b[0m\n\u001b[0;32m     13\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m7\u001b[39m,  \u001b[38;5;66;03m# Set an appropriate integer value for max_depth\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Add other parameters as needed\u001b[39;00m\n\u001b[0;32m     18\u001b[0m }\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 4. Train the XGBoost model with the correct features\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Assuming X_train and y_train are NumPy arrays\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Convert them to DataFrames\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m df_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(df_test, columns\u001b[38;5;241m=\u001b[39mdf_train\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Ensure the features in training and test sets are aligned\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:785\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    774\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    775\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    776\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    782\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    783\u001b[0m         )\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 785\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32mc:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    334\u001b[0m )\n\u001b[1;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (800, 20), indices imply (800, 32)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "# 1. Check and display the columns of the training and test sets\n",
    "print(\"Training Set Columns:\", df_train.columns)\n",
    "print(\"Test Set Columns:\", df_test.columns)\n",
    "\n",
    "# 2. Check the number of features in the training and test sets\n",
    "print(\"Number of Features in Training Set:\", len(df_train.columns))\n",
    "print(\"Number of Features in Test Set:\", len(df_test.columns))\n",
    "\n",
    "# 3. Define and initialize the hyperparameters for XGBoost\n",
    "params = {\n",
    "    'max_depth': 7,  # Set an appropriate integer value for max_depth\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100,\n",
    "    # Add other parameters as needed\n",
    "}\n",
    "\n",
    "# 4. Train the XGBoost model with the correct features\n",
    "# Assuming X_train and y_train are NumPy arrays\n",
    "# Convert them to DataFrames\n",
    "X_train = pd.DataFrame(X_train, columns=df_train.columns)\n",
    "df_test = pd.DataFrame(df_test, columns=df_train.columns)\n",
    "\n",
    "# Ensure the features in training and test sets are aligned\n",
    "common_features = set(X_train.columns) & set(df_test.columns)\n",
    "X_train = X_train[common_features]\n",
    "df_test = df_test[common_features]\n",
    "\n",
    "# Train the model\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Make predictions on the test set\n",
    "y_pred = pd.DataFrame(model.predict(df_test), columns=['NObeyesdad'])\n",
    "\n",
    "# Create a DataFrame for submission\n",
    "df_submission = pd.concat([df_test['id'], y_pred], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(alpha=0.112, base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None, lambda=2.653,\n",
       "              learning_rate=0.3, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=12,\n",
       "              max_leaves=None, min_child_weight=0.4004, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(alpha=0.112, base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None, lambda=2.653,\n",
       "              learning_rate=0.3, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=12,\n",
       "              max_leaves=None, min_child_weight=0.4004, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(alpha=0.112, base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None, lambda=2.653,\n",
       "              learning_rate=0.3, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=12,\n",
       "              max_leaves=None, min_child_weight=0.4004, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, ...)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_opti = {'eval_metric': 'logloss',\n",
    "              'max_depth': int(12.0),\n",
    "              'min_child_weight': 0.4004,\n",
    "              'subsample': 1.0,\n",
    "              'gamma': 0,\n",
    "              'colsample_bytree': 0.9,\n",
    "              'alpha': 0.112,\n",
    "              'lambda': 2.653,\n",
    "              'learning_rate': 0.3,\n",
    "              'use_label_encoder': False,\n",
    "              'objective': 'binary:logistic',\n",
    "              'seed': 42}\n",
    "\n",
    "model = xgb.XGBClassifier(**params_opti)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 20, got 30",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNObeyesdad\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m df_submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m], y_pred], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m df_submission\n",
      "File \u001b[1;32mc:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py:1553\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1545\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1546\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1550\u001b[0m     iteration_range: Optional[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1551\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m-> 1553\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[0;32m   1561\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32mc:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py:1168\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1168\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m   1177\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\grove\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:2428\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2424\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2425\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2426\u001b[0m         )\n\u001b[0;32m   2427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features() \u001b[38;5;241m!=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m-> 2428\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2429\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature shape mismatch, expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2430\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2431\u001b[0m         )\n\u001b[0;32m   2433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_np_array_like(data):\n\u001b[0;32m   2434\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ensure_np_dtype\n",
      "\u001b[1;31mValueError\u001b[0m: Feature shape mismatch, expected: 20, got 30"
     ]
    }
   ],
   "source": [
    "y_pred = pd.DataFrame(model.predict(df_test.drop('id', axis=1)), columns = ['NObeyesdad'])\n",
    "\n",
    "df_submission = pd.concat([df_test['id'], y_pred], axis = 1)\n",
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission['NObeyesdad'] = df_submission['NObeyesdad'].map(lambda x : unencodeTarget(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('submissionXgb.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.loc[df_submission['NObeyesdad'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training XGBoost model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mparams\u001b[49m)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "# Training XGBoost model\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
